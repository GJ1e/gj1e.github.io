<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Gao J1e&#39;s Blog</title>
        <link>https://gj1e.github.io/posts/</link>
        <description>Recent content in Posts on Gao J1e&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>郜杰</copyright>
        <lastBuildDate>Tue, 15 Oct 2019 23:16:32 +0800</lastBuildDate>
        <atom:link href="https://gj1e.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Offer10_2</title>
            <link>https://gj1e.github.io/posts/2019/10/offer10_2/</link>
            <pubDate>Tue, 15 Oct 2019 23:16:32 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/offer10_2/</guid>
            <description></description>
            <content type="html"><![CDATA[]]></content>
        </item>
        
        <item>
            <title>Offer10_1</title>
            <link>https://gj1e.github.io/posts/2019/10/offer10_1/</link>
            <pubDate>Tue, 15 Oct 2019 23:16:23 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/offer10_1/</guid>
            <description></description>
            <content type="html"><![CDATA[]]></content>
        </item>
        
        <item>
            <title>Offer10</title>
            <link>https://gj1e.github.io/posts/2019/10/offer10/</link>
            <pubDate>Tue, 15 Oct 2019 23:14:53 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/offer10/</guid>
            <description></description>
            <content type="html"><![CDATA[]]></content>
        </item>
        
        <item>
            <title>剑指Offer(Java实现)09题</title>
            <link>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B009%E9%A2%98/</link>
            <pubDate>Tue, 15 Oct 2019 23:14:41 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B009%E9%A2%98/</guid>
            <description>面试题09：用两个栈实现队列  题目：  用两个栈实现一个队列。完成队列的Push和Pop操作。队列中的元素为int类型。    思路：
 栈的特点是先进后厨，队列的特点是先进先出。 队列：入队顺序：1，2，3，4；出队顺序：1，2，3，4 栈：Push顺序：1，2，3，4；Pop顺序：4，3，2，1
 首先插入元素1，随便把它插入哪个栈，比如我们就把它插入stack1，此时stack1中的元素有{1}，stack2为空。
 在压入两个元素2，3还是插入stack1，此时stack1中的元素有{1，2，3}其中元素3位于栈顶。这时如果删除一个元素，按照队列先进先出的规则，应该删除元素1。但是元素1并不位于栈顶，因此不能直接删除，如果我们把stack1中的元素依次弹出并压入stack2中，则stack2中元素的顺序正好和stack1中的顺序相反，stack2中元素的顺序为{3，2，1}.这是元素1就位于栈顶了，就可以直接弹出了，且stack2中所有元素的弹出顺序都和队列出队的顺序一样。
 因此可以总结出，当stack2不位空时，stack2中的栈顶元素就是最先入队列的元素，直接弹出即可。当stack2位空时，我们可就把stack1中的元素逐个弹出并压入stack2中。如果接下来在插入一个元素4，则还是把它压入stack1。
   /** * @Author GJ1e * @Create 2019/10/15 * @Time 18:39 * */ public class Sloution { Stack&amp;lt;Integer&amp;gt; stack1 = new Stack&amp;lt;Integer&amp;gt;(); Stack&amp;lt;Integer&amp;gt; stack2 = new Stack&amp;lt;Integer&amp;gt;(); //队列的Push操作。 public void Push(int elemen){ stack1.push(elemen); } //队列的Pop操作 public int Pop(){ if (stack1.empty() &amp;amp;&amp;amp; stack2.empty()) throw new RuntimeException(&amp;quot;请添加元素&amp;quot;); if (stack2.empty()){ //stack2为空就把stack1中的元素弹出并压入stack2中。 while (!</description>
            <content type="html"><![CDATA[

<h2 id="面试题09-用两个栈实现队列">面试题09：用两个栈实现队列</h2>

<ul>
<li><strong>题目：</strong>

<ul>
<li>用两个栈实现一个队列。完成队列的Push和Pop操作。队列中的元素为int类型。</li>
</ul></li>
</ul>

<hr />

<ul>
<li><p><strong>思路：</strong></p>

<ul>
<li>栈的特点是先进后厨，队列的特点是先进先出。</li>
<li>队列：入队顺序：1，2，3，4；出队顺序：1，2，3，4</li>

<li><p>栈：Push顺序：1，2，3，4；Pop顺序：4，3，2，1</p></li>

<li><p>首先插入元素1，随便把它插入哪个栈，比如我们就把它插入stack1，此时stack1中的元素有{1}，stack2为空。</p></li>

<li><p>在压入两个元素2，3还是插入stack1，此时stack1中的元素有{1，2，3}其中元素3位于栈顶。这时如果删除一个元素，按照队列先进先出的规则，应该删除元素1。但是元素1并不位于栈顶，因此不能直接删除，如果我们把stack1中的元素依次弹出并压入stack2中，则stack2中元素的顺序正好和stack1中的顺序相反，stack2中元素的顺序为{3，2，1}.这是元素1就位于栈顶了，就可以直接弹出了，且stack2中所有元素的弹出顺序都和队列出队的顺序一样。</p></li>

<li><p>因此可以总结出，当stack2不位空时，stack2中的栈顶元素就是最先入队列的元素，直接弹出即可。当stack2位空时，我们可就把stack1中的元素逐个弹出并压入stack2中。如果接下来在插入一个元素4，则还是把它压入stack1。</p></li>
</ul></li>
</ul>

<hr />

<pre><code class="language-java">/**
 * @Author GJ1e
 * @Create 2019/10/15
 * @Time 18:39
 *
 */
public class Sloution {
    Stack&lt;Integer&gt; stack1 = new Stack&lt;Integer&gt;();
    Stack&lt;Integer&gt; stack2 = new Stack&lt;Integer&gt;();

    //队列的Push操作。
    public void Push(int elemen){
        stack1.push(elemen);
    }

    //队列的Pop操作
    public int Pop(){
        if (stack1.empty() &amp;&amp; stack2.empty())
            throw new RuntimeException(&quot;请添加元素&quot;);
        if (stack2.empty()){    //stack2为空就把stack1中的元素弹出并压入stack2中。
            while (!stack1.empty())
            stack2.push(stack1.pop());
        }
        return stack2.pop();    //弹出stack2中的栈顶元素。
    }
}

</code></pre>

<hr />

<p><strong>此代码已在牛客网AC</strong></p>
]]></content>
        </item>
        
        <item>
            <title>剑指Offer(Java实现)08题</title>
            <link>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B008%E9%A2%98/</link>
            <pubDate>Tue, 15 Oct 2019 23:14:33 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B008%E9%A2%98/</guid>
            <description>面试题08：二叉树的下一个节点  题目：  给定一棵二叉树和其中的一个节点，如何找出中序遍历的下一个节点？树中的节点除了有两个分别指向左、右子节点的指针，还有一个指向父节点的指针。    思路：
 二叉树中序遍历序列的顺序：左，根，右。 根据二叉树中序遍历的规则，我们可以将树中的节点分为以下几种情况：
 1、节点有右子树，那么它的下一个节点，就是它自己的右子树中的最左子节点。
 (也就是从右子节点出发，一直沿着指向左子节点的指针，就能找到它的下一个节点)
 2、节点没有右子树，并且还是自己父节点的左子节点，那么它的下一个节点就是自己的父节点。
 3、节点没有右子树，并且还是自己父节点的右子节点。对于这样的节点，我们可以沿着它指向父节点的指针一直向上遍历，直到找到一个是自己父节点的左子节点的节点。如果这样的节点存在，那么这个节点的父节点就是我们要找的下一个节点。
   /** * @Author GJ1e * @Create 2019/10/10 * @Time 20:30 * */ public class Solution { //定义二叉树结构体 class BinaryTreeNode{ int vaule; BinaryTreeNode left = null; BinaryTreeNode right = null; BinaryTreeNode parent = null; public BinaryTreeNode(int vaule){ this.vaule = vaule; } } public BinaryTreeNode getNextNode(BinaryTreeNode pNode){ if (pNode==null) return null; BinaryTreeNode pNext = null; if (pNext.</description>
            <content type="html"><![CDATA[

<h2 id="面试题08-二叉树的下一个节点">面试题08：二叉树的下一个节点</h2>

<ul>
<li><strong>题目：</strong>

<ul>
<li>给定一棵二叉树和其中的一个节点，如何找出中序遍历的下一个节点？树中的节点除了有两个分别指向左、右子节点的指针，还有一个指向父节点的指针。</li>
</ul></li>
</ul>

<hr />

<ul>
<li><p><strong>思路：</strong></p>

<ul>
<li>二叉树中序遍历序列的顺序：左，根，右。</li>

<li><p>根据二叉树中序遍历的规则，我们可以将树中的节点分为以下几种情况：</p></li>

<li><p>1、节点有右子树，那么它的下一个节点，就是它自己的右子树中的最左子节点。</p></li>

<li><p>(也就是从右子节点出发，一直沿着指向左子节点的指针，就能找到它的下一个节点)</p></li>

<li><p>2、节点没有右子树，并且还是自己父节点的左子节点，那么它的下一个节点就是自己的父节点。</p></li>

<li><p>3、节点没有右子树，并且还是自己父节点的右子节点。对于这样的节点，我们可以沿着它指向父节点的指针一直向上遍历，直到找到一个是自己父节点的左子节点的节点。如果这样的节点存在，那么这个节点的父节点就是我们要找的下一个节点。</p></li>
</ul></li>
</ul>

<hr />

<pre><code class="language-java">
/**
 * @Author GJ1e
 * @Create 2019/10/10
 * @Time 20:30
 *
 */
public class Solution {
    //定义二叉树结构体
    class BinaryTreeNode{
        int vaule;
        BinaryTreeNode left = null;
        BinaryTreeNode right = null;
        BinaryTreeNode parent = null;

        public BinaryTreeNode(int vaule){
            this.vaule = vaule;
        }
    }

    public BinaryTreeNode getNextNode(BinaryTreeNode pNode){
        if (pNode==null) return null;

        BinaryTreeNode pNext = null;

        if (pNext.right != null){       //节点有右子树
            BinaryTreeNode Right = pNode.right;
            while (Right.left != null)
                Right = Right.left;

            pNext = Right;
        }else if (pNode.parent != null){       //节点没有右子树，且节点的父节点不为空
            BinaryTreeNode current = pNode;
            BinaryTreeNode Parent = pNode.parent;

            while (Parent != null &amp;&amp; current == current.right){     //节点的父节点不为空，且为自己父节点的右子节点
                current = Parent;
                Parent = Parent.parent;
            }
            pNext = Parent;         // 节点是自己父节点的左子节点情况，下一个节点就是自己的父节点
        }
        return pNext;
    }
}


</code></pre>

<hr />

<p><strong>此代码已在牛客网AC</strong></p>
]]></content>
        </item>
        
        <item>
            <title>Offer07</title>
            <link>https://gj1e.github.io/posts/2019/10/offer07/</link>
            <pubDate>Tue, 15 Oct 2019 23:14:13 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/offer07/</guid>
            <description></description>
            <content type="html"><![CDATA[]]></content>
        </item>
        
        <item>
            <title>分布式一致性协议2PC&amp;3PC</title>
            <link>https://gj1e.github.io/posts/2019/10/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE2pc3pc/</link>
            <pubDate>Fri, 11 Oct 2019 17:50:15 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE2pc3pc/</guid>
            <description>在分布式系统中，每一个机器节点最然都能够，明确知道自己在进行事务操作的过程中是成功还是失败，但却无法直接获取其他分布式节点的操作结果。因为事务操作需要跨越多个分布式节点时，需要引入一个协调者统一调度所有节点的执行逻辑。
 2PC 2pc协议共分为提交事务请求，执行事务提交两个阶段。
阶段一：提交事务请求  事务询问
 协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。  执行事务
 各参与者节点执行事务操作，并将其操作写入到本地事务日志中。  各参与者向协调者反馈事务询问的响应
 如果参与者成功执行了事务操作，那么就反馈给协调者YES响应，表示事务可以执行。 如果参与者没有成功过事务操作，那么就反馈给协调者No响应，表示事务不可以执行。   阶段二：执行事务提交 在阶段二中协调者会根据参与者反馈的情况来决定，最终是否可以进行事务的提交操作。
 假如协调者收到参与者的反馈都是YES时，那么就会执行事务提交。
 协调者向所有参与者发送正式提交事务的请求(即Commit请求)。 参与者执行Commit请求，并释放整个事务期间占用的资源。 各参与者向协调者反馈ACK完成的消息。 协调者收到所有参与者反馈的ACK消息后，即完成事务提交。  假如协调者收到任何一个参与者反馈NO，那么就执行中断事务
 协调者向所有参与者发出回滚请求(即RollBack请求) 参与者根据阶段一事务日志中的操作执行回滚操作，并释放整个事务期间占用的资源。 各参与者向协调者反馈ACK完成的消息。 协调者收到所有参与者反馈的ACK消息后，完成事务中断。   2PC的缺陷  同步阻塞：即所偶参与的事务逻辑均处于阻塞状态。
 单点故障：协调者存在单点故障问题，如果协调者出现故障，参与者将一直处于锁定状态。
 脑裂问题：在阶段二中，如果只有部分参与者接受并执行了Commit请求，，会导致节点数据不一致。
  2PC的优点 原理简单，实现方便。
3PC 三阶段提交协议，是2pc的改进版本，即将事务的提交过程分为CanCommit，PreCommit，DoCommit三个阶段呢来进行处理。
阶段一：CanCommit  协调者向所有参与者发出包含事务内容的CanCommit请求，询问是否可以提交事务，并等待所有参与者的反馈。
 参与者收到CanCommit请求后，如果认为可以执行事务操作，则反馈YES，并进入预备状态，否则反馈NO。
  阶段二：PreCommit 此阶段分两种情况
 事务预提交：(所有参与者反馈YES时)
 协调者向所有参与者发出PreCommit请求，进入准备阶段。 参与者收到PreCommit请求后，执行事务操作，并记录到事务日志中。(但不提交事务) 各参与者向协调者反馈ACK响应或者NO响应，并等待最终指令。  中断事务：(任何一个参与者反馈NO或者等待超时后，协调者无法收到所有参与者的反馈时)</description>
            <content type="html"><![CDATA[

<blockquote>
<p>在分布式系统中，每一个机器节点最然都能够，明确知道自己在进行事务操作的过程中是成功还是失败，但却无法直接获取其他分布式节点的操作结果。因为事务操作需要跨越多个分布式节点时，需要引入一个协调者统一调度所有节点的执行逻辑。</p>
</blockquote>

<h2 id="2pc">2PC</h2>

<p>2pc协议共分为<strong>提交事务请求，执行事务提交</strong>两个阶段。</p>

<h3 id="阶段一-提交事务请求">阶段一：提交事务请求</h3>

<ol>
<li><p><strong>事务询问</strong></p>

<ul>
<li>协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。</li>
</ul></li>

<li><p><strong>执行事务</strong></p>

<ul>
<li>各参与者节点执行事务操作，并将其操作写入到本地事务日志中。</li>
</ul></li>

<li><p><strong>各参与者向协调者反馈事务询问的响应</strong></p>

<ul>
<li>如果参与者成功执行了事务操作，那么就反馈给协调者YES响应，表示事务可以执行。</li>
<li>如果参与者没有成功过事务操作，那么就反馈给协调者No响应，表示事务不可以执行。</li>
</ul></li>
</ol>

<hr />

<h3 id="阶段二-执行事务提交">阶段二：执行事务提交</h3>

<p>在阶段二中协调者会根据参与者反馈的情况来决定，最终是否可以进行事务的提交操作。</p>

<ul>
<li><p><strong>假如协调者收到参与者的反馈都是YES时，那么就会执行事务提交。</strong></p>

<ol>
<li>协调者向所有参与者发送正式提交事务的请求(即Commit请求)。</li>
<li>参与者执行Commit请求，并释放整个事务期间占用的资源。</li>
<li>各参与者向协调者反馈ACK完成的消息。</li>
<li>协调者收到所有参与者反馈的ACK消息后，即完成事务提交。</li>
</ol></li>

<li><p><strong>假如协调者收到任何一个参与者反馈NO，那么就执行中断事务</strong></p>

<ol>
<li>协调者向所有参与者发出回滚请求(即RollBack请求)</li>
<li>参与者根据阶段一事务日志中的操作执行回滚操作，并释放整个事务期间占用的资源。</li>
<li>各参与者向协调者反馈ACK完成的消息。</li>
<li>协调者收到所有参与者反馈的ACK消息后，完成事务中断。</li>
</ol></li>
</ul>

<hr />

<h3 id="2pc的缺陷">2PC的缺陷</h3>

<ul>
<li><p><strong>同步阻塞：</strong>即所偶参与的事务逻辑均处于阻塞状态。</p></li>

<li><p><strong>单点故障：</strong>协调者存在单点故障问题，如果协调者出现故障，参与者将一直处于锁定状态。</p></li>

<li><p><strong>脑裂问题：</strong>在阶段二中，如果只有部分参与者接受并执行了Commit请求，，会导致节点数据不一致。</p></li>
</ul>

<h3 id="2pc的优点">2PC的优点</h3>

<p>原理简单，实现方便。</p>

<hr />

<h2 id="3pc">3PC</h2>

<p>三阶段提交协议，是2pc的改进版本，即将事务的提交过程分为<strong>CanCommit，PreCommit，DoCommit</strong>三个阶段呢来进行处理。</p>

<h3 id="阶段一-cancommit">阶段一：CanCommit</h3>

<ol>
<li><p>协调者向所有参与者发出包含事务内容的CanCommit请求，询问是否可以提交事务，并等待所有参与者的反馈。</p></li>

<li><p>参与者收到CanCommit请求后，如果认为可以执行事务操作，则反馈YES，并进入预备状态，否则反馈NO。</p></li>
</ol>

<hr />

<h3 id="阶段二-precommit">阶段二：PreCommit</h3>

<p><strong>此阶段分两种情况</strong></p>

<ol>
<li><p><strong>事务预提交：(所有参与者反馈YES时)</strong></p>

<ul>
<li>协调者向所有参与者发出PreCommit请求，进入准备阶段。</li>
<li>参与者收到PreCommit请求后，执行事务操作，并记录到事务日志中。<strong>(但不提交事务)</strong></li>
<li>各参与者向协调者反馈ACK响应或者NO响应，并等待最终指令。</li>
</ul></li>

<li><p><strong>中断事务：(任何一个参与者反馈NO或者等待超时后，协调者无法收到所有参与者的反馈时)</strong></p>

<ul>
<li>协调者向所有参与者发出abort(中止)请求。</li>
<li>无论是收到协调者发出的abort请求，或者在等待协调者请求过程中出现超时，均会中断事务。</li>
</ul></li>
</ol>

<hr />

<h3 id="阶段三-docommit">阶段三：DoCommit</h3>

<p><strong>此阶段也存在两种情况</strong></p>

<ol>
<li><p><strong>提交事务：(所有参与者反馈YES响应时)</strong></p>

<ul>
<li>如果协调者处于工作状态，则向所有的参与者发送DoCommit请求。</li>
<li>各参与者收到DoCommit请求后，会正式执行事务提交，并释放整个事务期间占用的资源。</li>
<li>各参与者向协调者发送ACK，反馈完成的消息。</li>
<li>协调者收到所有参与者反馈的ACK消息后，即完成事务提交。</li>
</ul></li>

<li><p><strong>中断事务：(任何一个参与者反馈NO，或者等待超时后，协调者无法收到所有参与者的反馈时)</strong></p>

<ul>
<li>如果协调者处于工作状态，则向所有参与者发送abort请求。</li>
<li>参与者根据阶段二事务日志中的信息执行回滚操作，并释放整个事务期间占用的资源。</li>
<li>各参与者向协调者发送ACK反馈完成的消息。</li>
<li>协调者收到所有参与者反馈的ACK消息后，即完成事务中断。</li>
</ul></li>
</ol>

<blockquote>
<p><strong>进入阶段三之后，无论协调者出现问题，或者协调者和参与者网络出现问题，都会导致参与者无法接收到协调者发出的DoCommit请求或abort请求，此时参与者都会在等待超时之后继续执行事务提交。</strong></p>
</blockquote>

<hr />

<h3 id="3pc的优点">3PC的优点</h3>

<ul>
<li><p><strong>降低了阻塞范围</strong>：在等待超时后，协调者或参与者会中断事务。</p></li>

<li><p><strong>避免了协调者单点故障</strong>：阶段3中协调者出现问题时，参与者会继续提交事务。</p></li>
</ul>

<hr />

<h3 id="3pc的缺陷">3PC的缺陷</h3>

<ul>
<li>脑裂问题依然存在，即在所有参与者收到PreCommit请求后，等待最终指令。如果此时协调者无法和参与者正常通信，会导致参与者继续提交事务，造成数据的不一致。</li>
</ul>

<hr />

<blockquote>
<p>无论2PC或3PC均无法彻底解决分布式一致性问题，解决一致性问题唯有Paxos算法。</p>
</blockquote>

<hr />
]]></content>
        </item>
        
        <item>
            <title>ZAB集群数据同步过程</title>
            <link>https://gj1e.github.io/posts/2019/10/zab%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%BF%87%E7%A8%8B/</link>
            <pubDate>Fri, 11 Oct 2019 10:36:18 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/zab%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%BF%87%E7%A8%8B/</guid>
            <description> ZXID zxid是Zookeeper中事务的全局唯一ID。
ZXID有两部分组成：一部分为Leader的选举周期Epoch值；一部分为事务的递增计数器
同步过程  对于准Leadr，所有的Follower会向准Leader发送一个自己最后一次接受的事务的Epoch值。
 当准Leader收到集群中过半的Follower发送的Epoch值之后，在这些Epoch值中选出一个最大值，将这个值+1得到新的Epoch值，并将这个新的Epoch值发送给集群中的Follower。
 当Follower收到准Leader发送的Epoch值后，会将其与自己的Epoch值进行比较，若小于，则更新自己的Epoch值为新的值，并向Leader发送ACK信息，ACK信息中包含了自己的Epoch值和自己的历史事务集合。
 Leader收到Follower发送的ACK信息之后，会在所有的历史事务集合中选出一个ZXID为最大的历史事务集合作为自己的初始化事务集合。
 准Leader将Epoch值与初始化事务集合发送给集群中过半的Follower。Leader会为每一个Follower准备一个队列，并将那些没有被各个Follower同步的事务，以Proposal的形式发送给各个Follower，并在后面追加Commint消息，表示该事务已经被提交。
 当Follower收到后，会接受并执行初始化事务集合，然后反馈给准Leader表明自己已处理。
 当Leader收到Follower的反馈后，会向Follower发送Commint消息，Follower收到Commit消息后提交事务，完成数据同步。
  </description>
            <content type="html"><![CDATA[

<h2 id="zxid">ZXID</h2>

<p><strong>zxid是Zookeeper中事务的全局唯一ID。</strong></p>

<p>ZXID有两部分组成：<strong>一部分为Leader的选举周期Epoch值；一部分为事务的递增计数器</strong></p>

<hr />

<h2 id="同步过程">同步过程</h2>

<ol>
<li><p>对于准Leadr，所有的Follower会向准Leader发送一个自己最后一次接受的事务的Epoch值。</p></li>

<li><p>当准Leader收到集群中过半的Follower发送的Epoch值之后，在这些Epoch值中选出一个最大值，将这个值+1得到新的Epoch值，并将这个新的Epoch值发送给集群中的Follower。</p></li>

<li><p>当Follower收到准Leader发送的Epoch值后，会将其与自己的Epoch值进行比较，若小于，则更新自己的Epoch值为新的值，并向Leader发送ACK信息，<strong>ACK信息中包含了自己的Epoch值和自己的历史事务集合。</strong></p></li>

<li><p>Leader收到Follower发送的ACK信息之后，会在所有的历史事务集合中选出一个<strong>ZXID为最大</strong>的历史事务集合作为自己的初始化事务集合。</p></li>

<li><p>准Leader将Epoch值与初始化事务集合发送给集群中过半的Follower。Leader会为每一个Follower准备一个队列，并将那些没有被各个Follower同步的事务，以Proposal的形式发送给各个Follower，并在后面追加Commint消息，表示该事务已经被提交。</p></li>

<li><p>当Follower收到后，会接受并执行初始化事务集合，然后反馈给准Leader表明自己已处理。</p></li>

<li><p>当Leader收到Follower的反馈后，会向Follower发送Commint消息，Follower收到Commit消息后提交事务，完成数据同步。</p></li>
</ol>

<hr />
]]></content>
        </item>
        
        <item>
            <title>剑指Offer(Java实现)06题</title>
            <link>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B006%E9%A2%98/</link>
            <pubDate>Tue, 08 Oct 2019 16:06:51 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B006%E9%A2%98/</guid>
            <description>面试题6：从尾到头打印链表  题目：  输入一个链表的头节点，从尾到头反过来打印出每个节点的值    思路1：
 遍历的顺序是从头到尾，输出的顺序是从尾到头。也就是说，第一个遍历的节点，最后一个输出；最后一个遍历的节点，第一个输出。这就是典型的“先进后出”。所以可以选择“栈”来解决这个问题。  思路2：
 这个题也可以用递归的方式来解，递归的本质就是一个栈结构。   import java.util.ArrayList; import java.util.Stack; public class Solution { //链表的定义 class ListNode{ int value; ListNode next = null; ListNode(int value){ this.value = value; } } public ArrayList&amp;lt;Integer&amp;gt; printListFromTailToHead(ListNode listNode){ ArrayList&amp;lt;Integer&amp;gt; arrayList = new ArrayList&amp;lt;Integer&amp;gt;(); if (listNode == null) //异常输入 return arrayList; Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;Integer&amp;gt;(); while(listNode!= null)	//链表压栈 { stack.push(listNode.value); listNode = listNode.</description>
            <content type="html"><![CDATA[

<h2 id="面试题6-从尾到头打印链表">面试题6：从尾到头打印链表</h2>

<ul>
<li><strong>题目：</strong>

<ul>
<li>输入一个链表的头节点，从尾到头反过来打印出每个节点的值</li>
</ul></li>
</ul>

<hr />

<ul>
<li><p><strong>思路1：</strong></p>

<ul>
<li>遍历的顺序是从头到尾，输出的顺序是从尾到头。也就是说，第一个遍历的节点，最后一个输出；最后一个遍历的节点，第一个输出。这就是典型的“先进后出”。所以可以选择“栈”来解决这个问题。</li>
</ul></li>

<li><p><strong>思路2：</strong></p>

<ul>
<li>这个题也可以用递归的方式来解，递归的本质就是一个栈结构。</li>
</ul></li>
</ul>

<hr />

<pre><code class="language-java">import java.util.ArrayList;
import java.util.Stack;

public class Solution {
	//链表的定义
    class ListNode{
        int value;
        ListNode next = null;

        ListNode(int value){
            this.value = value;
        }
    }

    public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode){
        ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();
        if (listNode == null)   //异常输入
            return arrayList;

        Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;();

        while(listNode!= null)	//链表压栈
        {
            stack.push(listNode.value);
            listNode = listNode.next;
        }

        while (!stack.empty()) //栈为空返回true；链表出栈
        {
            arrayList.add(stack.pop().intValue());
        }

        return arrayList;
    }
}

</code></pre>

<hr />

<p><strong>此代码已在牛客网AC</strong></p>
]]></content>
        </item>
        
        <item>
            <title>剑指Offer(Java实现)05题</title>
            <link>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B005%E9%A2%98/</link>
            <pubDate>Tue, 08 Oct 2019 15:27:20 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B005%E9%A2%98/</guid>
            <description>面试题5：替换空格  题目：  请实现一个函数，将一个字符串中的每个空格替换成“%20”。 例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy.    思路：  就是一个空格变成了%20，也就是说每有一个空格，长度要增加2，所以首先先计算有多少个空格，这样长度就能增加多少，得到增加后的长度Length。 然后new一个Length长度的字符数组，从尾到头开始复制原来的数组，如果复制过程中，如果字符不是空格，直接复制，如果字符是空格，那么需要把这个空格变成%20（这个复制过程就是把新建的数组比如现在到了 K这个位置，然后就是K，K-1，K-2这三个位置依次变成0,2，%这三个字符，因为是从后往前复制的所以是倒序），重复这个过程就行。   方法一 /** * @Author GJ1e * @Create 2019/9/11 * @Time 20:17 */ public class Solution { public String replaceSpace(StringBuffer str) { if(str==null) return null; int space = 0; for(int i=0;i&amp;lt;str.length();i++){ //记录空格数量 if(str.charAt(i)==&#39; &#39;) space++; } int indexOld = str.length()-1; //原字符串末尾 int newStrLength = str.length()+2*space; //新字符串长度 int indexNew = newStrLength-1; //新字符串末尾 str.setLength(newStrLength); //增加原字符串的长度，防止下标越界 while(indexOld !</description>
            <content type="html"><![CDATA[

<h2 id="面试题5-替换空格">面试题5：替换空格</h2>

<ul>
<li><strong>题目</strong>：

<ul>
<li>请实现一个函数，将一个字符串中的每个空格替换成“%20”。</li>
<li>例如，当字符串为<strong>We Are Happy.</strong>则经过替换之后的字符串为<strong>We%20Are%20Happy.</strong></li>
</ul></li>
</ul>

<hr />

<ul>
<li><strong>思路</strong>：

<ul>
<li>就是一个空格变成了%20，也就是说每有一个空格，长度要增加2，所以首先先计算有多少个空格，这样长度就能增加多少，得到增加后的长度Length。</li>
<li>然后new一个Length长度的字符数组，从尾到头开始复制原来的数组，如果复制过程中，如果字符不是空格，直接复制，如果字符是空格，那么需要把这个空格变成%20（这个复制过程就是把新建的数组比如现在到了 K这个位置，然后就是K，K-1，K-2这三个位置依次变成0,2，%这三个字符，因为是从后往前复制的所以是倒序），重复这个过程就行。</li>
</ul></li>
</ul>

<hr />

<h3 id="方法一">方法一</h3>

<pre><code class="language-java">/**
 * @Author GJ1e
 * @Create 2019/9/11
 * @Time 20:17
 */
public class Solution {
	public String replaceSpace(StringBuffer str) {
    	if(str==null)
        	return null;

        int space = 0;
        for(int i=0;i&lt;str.length();i++){ //记录空格数量
        	if(str.charAt(i)==' ')
                space++;
            }

        int indexOld = str.length()-1; //原字符串末尾
        int newStrLength = str.length()+2*space; //新字符串长度
        int indexNew = newStrLength-1; //新字符串末尾
        str.setLength(newStrLength); //增加原字符串的长度，防止下标越界

        while(indexOld != indexNew){ //当新字符串指针等于原字符串指针时，说明空格全部替换完毕。
            if(str.charAt(indexOld)==' ') //等于空格进行替换
            {
                indexOld--;
                str.setCharAt(indexNew--,'0'); 
                str.setCharAt(indexNew--,'2');
                str.setCharAt(indexNew--,'%');
            }
            else
            {     //不为空格则复制
                str.setCharAt(indexNew--,str.charAt(indexOld--));
            }
        }
        return str.toString();
    }
}


</code></pre>

<hr />

<h3 id="方法二">方法二</h3>

<pre><code class="language-java">/**
 * @Author GJ1e
 * @Create 2019/9/11
 * @Time 20:17
 */
public class Solution {


    public String replaceSpace(StringBuffer str){

        String str1 = str.toString(); //判断非法输入
        if (str1.equals(&quot;&quot;))
            return str1;

        char[] strArray = str1.toCharArray(); //把字符串转换成字符数组
        int i = 0;
        int lengthSpace = 0; //记录字符串数组中的空格数

        while(i&lt;strArray.length){

            if (strArray[i] == ' ')
                lengthSpace++;
            i++;
        }

        int newStrLength = strArray.length + lengthSpace*2;
        char[] newStr = new char[newStrLength];

        int j = strArray.length-1;
        i = newStr.length-1;

        while(j&gt;=0){

            if(strArray[j] != ' ')
            {
                newStr[i--] = strArray[j--];
            }else{
                newStr[i--] = '0';
                newStr[i--] = '2';
                newStr[i--] = '%';
                j--;
            }
        }
        return new String(newStr);

    }
}

</code></pre>

<hr />

<p>方法一、方法二思想一样，就是写法不一样，一个用的库函数比较多，另一个比较少。
两段代码都在牛客网AC了</p>
]]></content>
        </item>
        
        <item>
            <title>剑指Offer(Java实现)04题</title>
            <link>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B004%E9%A2%98/</link>
            <pubDate>Tue, 08 Oct 2019 11:41:26 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/%E5%89%91%E6%8C%87offerjava%E5%AE%9E%E7%8E%B004%E9%A2%98/</guid>
            <description>面试题4：二维数组中的查找  题目：  在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。    思路：
 就是比较矩阵的右上角的数与target的大小，如果target比这个矩阵右上角的数大，由于矩阵的右上角元素A是A所在行的最大的值，所以target肯定不在A所在的行了，所以这时候就应该就在除去第一行的剩下的行中去找这个target； 如果target比矩阵右上角的数A小，那么由于A所在的列中A是最小的，那么target就在除去最右边的列的其它的列； 如果相等，返回true；   /** * @Author GJ1e * @Create 2019/9/11 * @Time 18:58 */ public class Solution { public boolean arrayFind(int target , int[][] array){ //检查异常输入 if(array==null || array.length&amp;lt;0 || array[0].length&amp;lt;0) return false; int rows = 0; //行 int cols = array[0].length-1; //列 while(rows&amp;lt;=array.length-1 &amp;amp;&amp;amp; cols&amp;gt;=0){ if(target&amp;gt;array[rows][cols]) //target大于矩阵左上角的数，说明target大于这一行上的所有数 rows++; //进入下一行继续比较 else if(target&amp;lt;array[rows][cols]) //target小于矩阵左上角的数，说明target小于这一列上的所有数 cols--; //进入下一列继续比较 else //找到target return true; } return false; } }  此代码在牛客网已AC</description>
            <content type="html"><![CDATA[

<h2 id="面试题4-二维数组中的查找">面试题4：二维数组中的查找</h2>

<ul>
<li><strong>题目</strong>：

<ul>
<li>在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</li>
</ul></li>
</ul>

<hr />

<ul>
<li><p><strong>思路</strong>：</p>

<ul>
<li>就是比较矩阵的右上角的数与target的大小，如果target比这个矩阵右上角的数大，由于矩阵的右上角元素A是A所在行的最大的值，所以target肯定不在A所在的行了，所以这时候就应该就在除去第一行的剩下的行中去找这个target；</li>
<li>如果target比矩阵右上角的数A小，那么由于A所在的列中A是最小的，那么target就在除去最右边的列的其它的列；</li>
<li>如果相等，返回true；</li>
</ul></li>
</ul>

<hr />

<pre><code class="language-java">
	/**
	 * @Author GJ1e
	 * @Create 2019/9/11
 	 * @Time 18:58
 	 */

	public class Solution {
	
	    public boolean arrayFind(int target , int[][] array){
	        //检查异常输入
	        if(array==null || array.length&lt;0 || array[0].length&lt;0)
	            return false;
	
	        int rows = 0;   //行
	        int cols = array[0].length-1;   //列
	
	        while(rows&lt;=array.length-1 &amp;&amp; cols&gt;=0){
	            if(target&gt;array[rows][cols]) //target大于矩阵左上角的数，说明target大于这一行上的所有数
	                rows++;                  //进入下一行继续比较
	            else if(target&lt;array[rows][cols]) //target小于矩阵左上角的数，说明target小于这一列上的所有数
	                cols--;                       //进入下一列继续比较
	            else         //找到target
	                return true;
	        }
	        return false;
	    }
	}



</code></pre>

<p><strong>此代码在牛客网已AC</strong></p>

<hr />
]]></content>
        </item>
        
        <item>
            <title>Dubbo</title>
            <link>https://gj1e.github.io/posts/2019/10/dubbo/</link>
            <pubDate>Mon, 07 Oct 2019 20:53:26 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/dubbo/</guid>
            <description>Dubbo简介 Dubbo是一个分布式服务框架，以及SOA治理方案。其主要功能包括：
 高性能NIO通讯以多协议集成 服务动态寻址与路由 软负载均衡与容错 依赖分析与降级  Dubbo的五个节点  Provider：暴露服务的服务提供方
 Consumer：调用远程服务的服务消费方
 Registry：服务注册与发现的中心
 Monitor ：统计服务的调用次数和调用时间的监控中心
 Container：服务运行容器
  Dubbo节点的调用过程  服务容器负责启动、加载，运行服务提供者
 服务提供者在启动时，向注册中心注册自己提供的服务
 服务消费者在启动时，向注册中心订阅自己所需的服务
 注册中心返回服务提供者地址列表给服务消费者。如果有变更，注册中心会基于长链接推送变更数据给服务消费者
 服务消费者从服务提供者地址列表中，基于软负载均衡算法选一台服务提供者进行调用。如果调用失败，再另选一台
 服务消费者和服务提供者，把在内存中累计调用次数和调用时间，定时每分钟向注册中心发送一次数据。
  Dubbo的四个特性  连通性：
 说明它们之间都存在着联系。例如Provider，Consumer和Registry三者之间都是长链接，而Provider，Consumer向Registry注册服务以及订阅服务的时间都得向Monitor汇报。  健壮性：
 说明具有稳定性，例如注册中心中的对等集群中任意一台服务器宕掉后，将会自动切换到另一台。就算注册中心全部宕掉，服务者和消费者依然可以通过本地缓存进行通讯。  伸缩性：
 可以通过增加机器部署实例进行添加新的注册中心和服务提供者。  升级性：
 就是对未来架构的设想，比起目前框架，它的特点是可以实现自动部署服务的本地代理，以及可以通过访问压力来自动增减服务提供者。   Dubbo的RPC  RPC(Remote Procedure Call)远程过程调用，他是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。 RPC协议假定某些传输协议的存在，如TCP,UDP,为通信程序之间携带信息数据。RPC使得开发网络分布式程序变得更加容易。
 Dubbo RPC调用过程  Client服务消费方以本地调用的方式调用服务。
 Client Stub接收到调用后负责将方法、参数等组装成可以进行网络传输的消息体。</description>
            <content type="html"><![CDATA[

<h2 id="dubbo简介">Dubbo简介</h2>

<p>Dubbo是一个分布式服务框架，以及SOA治理方案。其主要功能包括：</p>

<ul>
<li>高性能NIO通讯以多协议集成</li>
<li>服务动态寻址与路由</li>
<li>软负载均衡与容错</li>
<li>依赖分析与降级</li>
</ul>

<hr />

<h2 id="dubbo的五个节点">Dubbo的五个节点</h2>

<ul>
<li><p><strong>Provider</strong>：暴露服务的服务提供方</p></li>

<li><p><strong>Consumer</strong>：调用远程服务的服务消费方</p></li>

<li><p><strong>Registry</strong>：服务注册与发现的中心</p></li>

<li><p><strong>Monitor</strong> ：统计服务的调用次数和调用时间的监控中心</p></li>

<li><p><strong>Container</strong>：服务运行容器</p></li>
</ul>

<hr />

<h2 id="dubbo节点的调用过程">Dubbo节点的调用过程</h2>

<p><img src="/images/Dubbo节点调用流程.png" alt="Dubbo节点调用流程" /></p>

<ol>
<li><p>服务容器负责启动、加载，运行服务提供者</p></li>

<li><p>服务提供者在启动时，向注册中心注册自己提供的服务</p></li>

<li><p>服务消费者在启动时，向注册中心订阅自己所需的服务</p></li>

<li><p>注册中心返回服务提供者地址列表给服务消费者。如果有变更，注册中心会基于长链接推送变更数据给服务消费者</p></li>

<li><p>服务消费者从服务提供者地址列表中，基于软负载均衡算法选一台服务提供者进行调用。如果调用失败，再另选一台</p></li>

<li><p>服务消费者和服务提供者，把在内存中累计调用次数和调用时间，定时每分钟向注册中心发送一次数据。</p></li>
</ol>

<hr />

<h2 id="dubbo的四个特性">Dubbo的四个特性</h2>

<ol>
<li><p><strong>连通性</strong>：</p>

<ul>
<li>说明它们之间都存在着联系。例如Provider，Consumer和Registry三者之间都是长链接，而Provider，Consumer向Registry注册服务以及订阅服务的时间都得向Monitor汇报。</li>
</ul></li>

<li><p><strong>健壮性</strong>：</p>

<ul>
<li>说明具有稳定性，例如注册中心中的对等集群中任意一台服务器宕掉后，将会自动切换到另一台。就算注册中心全部宕掉，服务者和消费者依然可以通过本地缓存进行通讯。</li>
</ul></li>

<li><p><strong>伸缩性</strong>：</p>

<ul>
<li>可以通过增加机器部署实例进行添加新的注册中心和服务提供者。</li>
</ul></li>

<li><p><strong>升级性</strong>：</p>

<ul>
<li>就是对未来架构的设想，比起目前框架，它的特点是可以实现自动部署服务的本地代理，以及可以通过访问压力来自动增减服务提供者。</li>
</ul></li>
</ol>

<hr />

<h2 id="dubbo的rpc">Dubbo的RPC</h2>

<blockquote>
<p><strong>RPC(Remote Procedure Call)</strong>远程过程调用，他是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。
RPC协议假定某些传输协议的存在，如TCP,UDP,为通信程序之间携带信息数据。RPC使得开发网络分布式程序变得更加容易。</p>
</blockquote>

<hr />

<h2 id="dubbo-rpc调用过程">Dubbo RPC调用过程</h2>

<p><img src="/images/DubboRPC调用流程.png" alt="DubboRPC调用过程" /></p>

<ol>
<li><p>Client服务消费方以本地调用的方式调用服务。</p></li>

<li><p>Client Stub接收到调用后负责将方法、参数等组装成可以进行网络传输的消息体。</p></li>

<li><p>Client Stub找到服务者地址，并将消息发送到服务端。</p></li>

<li><p>Service Stub接收到消息后进行解码，并根据解码结果调用本地服务。</p></li>

<li><p>本地服务执行，并将结果返回给Service Stub</p></li>

<li><p>Service Stub将返回的结果打包成消息，并发送到服务消费方。</p></li>

<li><p>Client Stub接收到消息后进行解码。</p></li>

<li><p>服务消费方得到最终结果。</p></li>
</ol>
]]></content>
        </item>
        
        <item>
            <title>Zookeeper</title>
            <link>https://gj1e.github.io/posts/2019/10/zookeeper/</link>
            <pubDate>Mon, 07 Oct 2019 16:50:14 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/zookeeper/</guid>
            <description>简介  ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 &amp;mdash;百度百科
 ZooKeeper集群整体框架  Client：客户端。每个Client都可以去访问这个Zookeeper集群提供的服务。 Sever：服务器。为客户端提供服务。  Zookeeper把集群划分为三种角色：Leader，Follower，Observer(Zookeeper3.3引入)
 Leader：是所有的Follower通过选举产生的的一个主节点，它负责处理客户端所有的事务请求和集群中各服务器的调度。
 Follower：
 处理客户端非事务请求并转发事务请求给Leader。 参与Leader发起的事务请求提议的投票。（Leader发起提案，要求Follower进行投票，需要半数以上的Follower节点通过，Leader才会Commit数据）  Observer：与Follower一样，不同的是Observer不参与Leader选举，也不参与过半写成功策略。（Obsever的目的是为了在不影响集群写性能的前提下提升集群的读性能）
  事务与非事务请求的处理流程  事务：Client&amp;ndash;&amp;gt;Sever(Follower)发送一个请求，然后判断是一个事务请求，Follower就会把这个请求转发给Leader进行处理。
 非事务：Client&amp;ndash;&amp;gt;Sever(Follower)发送一个请求，然后判断是一个非事务请求，Follower就会直接处理给予响应。
  综上可以得出Zookeeper适合以查询（读操作）为主的业务场景，并不适合以事务修改（写操作）为主的业务场景。
 Zookeeper支持横向扩展，横向扩展只能加强Zookeeper非事务请求的处理，不能加强事务请求的处理，因为无论怎么横向扩展，也只能有一个Leader。
 客户端怎么判断向集群中哪个Sever发起请求  客户端自己维护着一份节点列表，它会有一个选择节点的算法，可以随机或者可以按照轮巡这种算法来选择一个节点进行请求。  Zookeeper节点类型  Znode有三种类型，临时的（Ephemeral）持久的（Persistent）和顺序的（Sequence） 临时Znode的生命周期与客户端会话相关，客户端会话结束时，Zookeeper会将临时Znode删除，临时Znode不可以有子节点 持久Znode不依赖于客户端会话，只有当客户端明确要删除该持久Znode时，才会被删除。 Znode类型在创建时确定，并且之后不能再修改 顺序Znode可以分为临时顺序节点和持久顺序节点。  持久顺序节点：客户端与Zookeeper断开连接之后该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号。 临时顺序节点：客户端与Zookeeper断开连接之后该节点会被删除，只是Zookeeper给该节点名称进行顺序编号。   Zookeeper数据模型  层次化目录结构，命名符合常规系统规范。
 每个节点在Zookeeper种叫做Znode，并且有一个唯一的路径标识。
 节点Znode可以包含数据和子节点，但是临时类型的节点不能有子节点。
 Znode种的数据可以有多个版本，比如某一个路径下有多个数据版本，那么查询这个路径下的数据就要带上版本。
  Zookeeper读写机制  Zookeeper是一个由多个Sever组成的集群。
 集群中只能有一个Leader，可以有多个Follower。
 每个Follower保存一份数据副本。
 全局数据一直</description>
            <content type="html"><![CDATA[

<h2 id="简介">简介</h2>

<blockquote>
<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。
ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 &mdash;百度百科</p>
</blockquote>

<hr />

<h2 id="zookeeper集群整体框架">ZooKeeper集群整体框架</h2>

<p><img src="/images/Zookeeper内部结构.png" alt="Zookeeper" /></p>

<ul>
<li>Client：<strong>客户端</strong>。每个Client都可以去访问这个Zookeeper集群提供的服务。</li>
<li>Sever：<strong>服务器</strong>。为客户端提供服务。</li>
</ul>

<p>Zookeeper把集群划分为三种角色：<strong>Leader，Follower，Observer(Zookeeper3.3引入)</strong></p>

<ul>
<li><p><strong>Leader</strong>：是所有的Follower通过选举产生的的一个主节点，它负责处理客户端所有的<strong>事务</strong>请求和集群中各服务器的调度。</p></li>

<li><p><strong>Follower</strong>：</p>

<ul>
<li>处理客户端<strong>非事务</strong>请求并转发<strong>事务</strong>请求给Leader。</li>
<li>参与Leader发起的事务请求提议的投票。（Leader发起提案，要求Follower进行投票，需要半数以上的Follower节点通过，Leader才会Commit数据）</li>
</ul></li>

<li><p><strong>Observer</strong>：与Follower一样，<strong>不同的是Observer不参与Leader选举，也不参与过半写成功策略。</strong>（Obsever的目的是为了在不影响集群写性能的前提下提升集群的读性能）</p></li>
</ul>

<h4 id="事务与非事务请求的处理流程">事务与非事务请求的处理流程</h4>

<ul>
<li><p>事务：Client&ndash;&gt;Sever(Follower)发送一个请求，然后判断是一个事务请求，Follower就会把这个请求转发给Leader进行处理。</p></li>

<li><p>非事务：Client&ndash;&gt;Sever(Follower)发送一个请求，然后判断是一个非事务请求，Follower就会直接处理给予响应。</p></li>
</ul>

<p><strong>综上可以得出Zookeeper适合以查询（读操作）为主的业务场景，并不适合以事务修改（写操作）为主的业务场景。</strong></p>

<blockquote>
<p>Zookeeper支持横向扩展，横向扩展只能加强Zookeeper非事务请求的处理，不能加强事务请求的处理，因为无论怎么横向扩展，也只能有一个Leader。</p>
</blockquote>

<hr />

<h2 id="客户端怎么判断向集群中哪个sever发起请求">客户端怎么判断向集群中哪个Sever发起请求</h2>

<ul>
<li>客户端自己维护着一份节点列表，它会有一个选择节点的算法，可以随机或者可以按照轮巡这种算法来选择一个节点进行请求。</li>
</ul>

<hr />

<h2 id="zookeeper节点类型">Zookeeper节点类型</h2>

<ol>
<li>Znode有三种类型，临时的（Ephemeral）持久的（Persistent）和顺序的（Sequence）</li>
<li>临时Znode的生命周期与客户端会话相关，客户端会话结束时，Zookeeper会将临时Znode删除，<strong>临时Znode不可以有子节点</strong></li>
<li>持久Znode不依赖于客户端会话，只有当客户端明确要删除该持久Znode时，才会被删除。</li>
<li>Znode类型在创建时确定，并且之后不能再修改</li>
<li>顺序Znode可以分为临时顺序节点和持久顺序节点。

<ul>
<li>持久顺序节点：客户端与Zookeeper断开连接之后该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号。</li>
<li>临时顺序节点：客户端与Zookeeper断开连接之后该节点会被删除，只是Zookeeper给该节点名称进行顺序编号。</li>
</ul></li>
</ol>

<hr />

<h2 id="zookeeper数据模型">Zookeeper数据模型</h2>

<p><img src="https://img-blog.csdn.net/20160830182309993" alt="Zookeeper数据模型" /></p>

<ul>
<li><p>层次化目录结构，命名符合常规系统规范。</p></li>

<li><p>每个节点在Zookeeper种叫做Znode，并且有一个唯一的路径标识。</p></li>

<li><p>节点Znode可以包含数据和子节点，但是临时类型的节点不能有子节点。</p></li>

<li><p>Znode种的数据可以有多个版本，比如某一个路径下有多个数据版本，那么查询这个路径下的数据就要带上版本。</p></li>
</ul>

<hr />

<h2 id="zookeeper读写机制">Zookeeper读写机制</h2>

<ul>
<li><p>Zookeeper是一个由多个Sever组成的集群。</p></li>

<li><p>集群中只能有一个Leader，可以有多个Follower。</p></li>

<li><p>每个Follower保存一份数据副本。</p></li>

<li><p>全局数据一直</p></li>

<li><p>分布式读写</p></li>

<li><p>更新请求转发由Leader实施</p></li>
</ul>

<hr />

<h2 id="zookeeper-保证">Zookeeper 保证</h2>

<ul>
<li><p>Zookeeper集群中的每个节点都维护着一个队列，来自同一个Client的更新请求，暗器发送的顺序依次执行。</p></li>

<li><p>数据更新原子性，一次数据更新要么成功，要么失败。</p></li>

<li><p>全局唯一数据视图，Client无论连接到哪个Server，数据视图都是一致的。</p></li>

<li><p>实时性，在一定时间范围内，Client能读到最新的数据。</p></li>
</ul>

<hr />

<h2 id="zookeeper的监听机制-watcher">Zookeeper的监听机制(Watcher)</h2>

<p><strong>Watcher</strong>：
在Zookeeper中是一个核心功能，Watcher可以监控目录节点的数据变化，以及子目录的变化。一旦这些状态发生变化，服务器就会通知所有设置在这个目录节点上的Watcher，从而每个客户端都很快知道它所关注的目录节点的状态发生变化，而做出相应的反应。</p>

<hr />

<h2 id="zookeeper底层实现数据一致性">Zookeeper底层实现数据一致性</h2>

<p><strong>主要通过事务日志，和数据快照来实现的。</strong></p>

<ul>
<li><p><strong>事务日志</strong></p>

<ul>
<li>事务日志记录了对Zookeeper的操作，文件以ZXID命名，可以快速定位到需要查询的事务。</li>
<li>事务日志采用磁盘预分配策略，未使用的部分写为0。避免每次追加数据都需要进行磁盘I/O为文件开辟新空间，其每个日志文件大小固定为64M。</li>
</ul></li>

<li><p><strong>数据快照</strong></p>

<ul>
<li>数据快照是Zokeeper数据存储的另一重要机制，用来记录某一时刻Zookeeper在内存中的全部数据内容，并将其写入指定的磁盘文件中，也是使用ZXID命名。</li>
<li>数据快照没有采用磁盘预分配策略，因此数据快照文件在一定程度上反映了当前Zookeeper的全量数据大小。</li>
</ul></li>
</ul>

<ol>
<li><p>对于每一次的客户端操作，都写入日志文件，同时更新Zookeeper的内存数据。在进行了若干次(SnapCount)操作之后，会将内存中的全量数据dump到本地文件，既数据快照。</p></li>

<li><p>为了避免Zookeeper中所有节点同时进行数据快照，Zookeeper采用过半随机策略。开始快照时，首先关闭当前日志文件，重新创建一个新的日志文件。并从内存中或许Zookeeper的全量数据和校验信息，并序列化写入到本地磁盘文件中，以本次写入的第一个事务的ZXID为后缀。</p></li>

<li><p>数据恢复时，会加载近100个快照文件，之所以有100个是因为，有可能最近的呢可快照文件校验不通过。若校验不通过，则继续向前解析，直到第一个可以正确校验的快照文件截止。</p></li>

<li><p>找到可以通过的校验快照文件之后，开始执行事务日志中的操作，此时即使不是最近的呢一个快照文件，我们也可以从快照文件中找到ZXID，便可以定位到具体事务文件从哪一个开始。</p></li>
</ol>

<hr />

<p>原创首发，如有转载请标明出处。                  ——GJ1e</p>
]]></content>
        </item>
        
        <item>
            <title>Memcached</title>
            <link>https://gj1e.github.io/posts/2019/10/memcached/</link>
            <pubDate>Fri, 04 Oct 2019 10:33:42 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/memcached/</guid>
            <description>简介Memchahed  Memcached是高性能分布式内存缓存服务器，它通过缓存数据库查询结果，减少对数据库的访问次数以提高动态Web应用的速度，提高可扩展性。 Memcached的API使用32位元的CRC(循环冗余校验)校验，计算键值后，将资料分散在不同的机器上，当表格满了以后，接下来新增的资料会以LRU机制替换掉。 Memcached基于一个存储键/值对的Hashmap。其守护进程是用C写的，但是客户端可以用任何语言来写，并通过mencached协议与其守护进程通信。  Memcached分布式算法 余数哈希  根据服务器的台数的余数进行分散。求得键的哈希值，再除以服务器的台数，根据余数选择服务器。  缺点：
 当添加或移除服务器时，缓存重组代价太大。当添加服务器要进行重哈希，会导致原来的服务器序号变了，按原来的逻辑寻找数据就会找不到，访问数据Memcached命中率下降，那么就会增加数据库服务器的负载。  一致性哈希  一致性hash算法通过一个叫作一致性hash环的数据结构实现。这个环的起点是0，终点是2^32 - 1，并且起点与终点连接，环的中间的整数按逆时针分布，故这个环的整数分布范围是[0, 2^32-1] 首先求出memcached服务器（节点）的哈希值，并将其配置到0~2^32-1的圆（continuum）上。 然后用同样的方法求出存储数据的键的哈希值，并映射到圆上。  然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过2^32-1仍然找不到服务器，就会保存到第一台memcached服务器上。   在Consistent Hashing中，只有在continuum上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响。
 Memcached的数据清除算法  LRU。每个slab会维护一个队列，刚插入的数据在队头，经常get的数据也会移动到队头，这样较老或者访问较少的数据相对都留在队尾。
 该算法从队尾开始淘汰，当slab分配不到足够的内存时，首先会检查队尾是否有过期数据。如果有的话会直接将其覆盖为新的对象，如果没有，会开始淘汰队尾的对象。
   Slab是一个内存块，它是memcached一次申请内存的最小单位。Slab的大小固定为1M（1048576 Byte），一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。
 描述一下Memcacehd的工作流程  先检查客户端的请求数据是否在memcached中，如有，直接把请求数据返回，不再对数据库进行任何操作； 如果请求的数据不在memcached中，就去查数据库，把从数据库中获取的数据返回给客户端，同时把数据缓存一份到memcached中（memcached客户端不负责，需要程序明确实现）； 每次更新数据库的同时更新memcached中的数据，保证一致性； 当分配给memcached内存空间用完之后，会使用LRU（Least Recently Used，最近最少使用）策略加上到期失效策略，失效数据首先被替换，然后再替换掉最近未使用的数据。  Memcached 和 Redis的区别  Redis不仅仅支持简单的k/v类型的数据，同时还提供string(字符串)、list(链表)、set(集合)、zset(sorted set &amp;ndash;有序集合)和hash（哈希类型）等数据结构的存储。 memcache支持简单的数据类型，String。
 Redis支持数据的备份，即master-slave模式的数据备份。
 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中
 redis的速度比memcached快很多
  Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型。
   有持久化需求或者对数据结构和处理有高级要求的应用，选择redis，其他简单的key/value存储，选择memcached。 对于两者的选择需要要看具体的应用场景，如果需要缓存的数据只是key-value这样简单的结构时，则还是采用memcache，它也足够的稳定可靠。 如果涉及到存储，排序等一系列复杂的操作时，毫无疑问选择redis。</description>
            <content type="html"><![CDATA[

<h2 id="简介memchahed">简介Memchahed</h2>

<ul>
<li>Memcached是高性能分布式内存缓存服务器，它通过缓存数据库查询结果，减少对数据库的访问次数以提高动态Web应用的速度，提高可扩展性。</li>
<li>Memcached的API使用32位元的CRC(循环冗余校验)校验，计算键值后，将资料分散在不同的机器上，<strong>当表格满了以后，接下来新增的资料会以LRU机制替换掉。</strong></li>
<li>Memcached基于一个存储<strong>键/值</strong>对的Hashmap。其守护进程是用C写的，但是客户端可以用任何语言来写，并通过mencached协议与其守护进程通信。</li>
</ul>

<hr />

<h2 id="memcached分布式算法">Memcached分布式算法</h2>

<h3 id="余数哈希">余数哈希</h3>

<ul>
<li>根据服务器的台数的余数进行分散。求得键的哈希值，再除以服务器的台数，根据余数选择服务器。</li>
</ul>

<p><strong>缺点：</strong></p>

<ul>
<li>当添加或移除服务器时，缓存重组代价太大。当添加服务器要进行重哈希，会导致原来的服务器序号变了，按原来的逻辑寻找数据就会找不到，访问数据Memcached命中率下降，那么就会增加数据库服务器的负载。</li>
</ul>

<hr />

<h3 id="一致性哈希">一致性哈希</h3>

<ul>
<li>一致性hash算法通过一个叫作一致性hash环的数据结构实现。这个环的起点是0，终点是2^32 - 1，并且起点与终点连接，环的中间的整数按逆时针分布，故这个环的整数分布范围是[0, 2^32-1]</li>
<li>首先求出memcached服务器（节点）的哈希值，并将其配置到0~2^32-1的圆（continuum）上。</li>
<li>然后用同样的方法求出存储数据的键的哈希值，并映射到圆上。 </li>
<li>然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过2^32-1仍然找不到服务器，就会保存到第一台memcached服务器上。</li>
</ul>

<blockquote>
<p><strong>在Consistent Hashing中，只有在continuum上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响。</strong></p>
</blockquote>

<p><img src="https://img-blog.csdn.net/20170108000506549?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGloYW8yMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="一致性哈希环" /></p>

<hr />

<h2 id="memcached的数据清除算法">Memcached的数据清除算法</h2>

<ul>
<li><p><strong>LRU。</strong>每个slab会维护一个队列，刚插入的数据在队头，经常get的数据也会移动到队头，这样较老或者访问较少的数据相对都留在队尾。</p></li>

<li><p>该算法从队尾开始淘汰，当slab分配不到足够的内存时，首先会检查队尾是否有过期数据。如果有的话会直接将其覆盖为新的对象，如果没有，会开始淘汰队尾的对象。</p></li>
</ul>

<blockquote>
<p>Slab是一个内存块，它是memcached一次申请内存的最小单位。Slab的大小固定为1M（1048576 Byte），一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。</p>
</blockquote>

<hr />

<h2 id="描述一下memcacehd的工作流程">描述一下Memcacehd的工作流程</h2>

<ul>
<li>先检查客户端的请求数据是否在memcached中，如有，直接把请求数据返回，不再对数据库进行任何操作；</li>
<li>如果请求的数据不在memcached中，就去查数据库，把从数据库中获取的数据返回给客户端，同时把数据缓存一份到memcached中（memcached客户端不负责，需要程序明确实现）；</li>
<li>每次更新数据库的同时更新memcached中的数据，保证一致性；</li>
<li>当分配给memcached内存空间用完之后，会使用LRU（Least Recently Used，最近最少使用）策略加上到期失效策略，失效数据首先被替换，然后再替换掉最近未使用的数据。</li>
</ul>

<hr />

<h2 id="memcached-和-redis的区别">Memcached 和 Redis的区别</h2>

<ul>
<li>Redis不仅仅支持简单的k/v类型的数据，同时还提供string(字符串)、list(链表)、set(集合)、zset(sorted set &ndash;有序集合)和hash（哈希类型）等数据结构的存储。</li>

<li><p>memcache支持简单的数据类型，String。</p></li>

<li><p>Redis支持数据的备份，即master-slave模式的数据备份。</p></li>

<li><p>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中</p></li>

<li><p>redis的速度比memcached快很多</p></li>

<li></li>

<li><p>Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型。</p></li>
</ul>

<blockquote>
<p>有持久化需求或者对数据结构和处理有高级要求的应用，选择redis，其他简单的key/value存储，选择memcached。
对于两者的选择需要要看具体的应用场景，如果需要缓存的数据只是key-value这样简单的结构时，则还是采用memcache，它也足够的稳定可靠。
如果涉及到存储，排序等一系列复杂的操作时，毫无疑问选择redis。</p>
</blockquote>

<hr />
]]></content>
        </item>
        
        <item>
            <title>Solr</title>
            <link>https://gj1e.github.io/posts/2019/10/solr/</link>
            <pubDate>Fri, 04 Oct 2019 09:36:34 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/solr/</guid>
            <description>Solr  Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。官网地址：http://lucene.apache.org/solr/  Solr原理  Solr是基于Lucene开发的全文检索服务器，而Lucene就是一套实现了全文检索的api，其本质就是一个全文检索的过程。全文检索就是把原始文档根据一定的规则拆分成若干个关键词，然后根据关键词创建索引，当查询时先查询索引找到对应的关键词，并根据关键词找到对应的文档，也就是查询结果，最终把查询结果展示给用户的过程  Solrd倒排索引  我们传统的方式（正排索引）是从关键点出发，然后再通过关键点找到关键点代表的信息中能够满足搜索条件的特定信息，既通过KEY寻找VALUE。 而Solr的搜索则是采用了倒排索引的方式，即通过VALUE找KEY。而在中文全文搜索中VALUE就是我们要搜索的单词，存放所有单词的地方叫词典。KEY是文档标号列表（通过文档标号列表我们可以找到出现过要搜索单词VALUE的文档）  Solr基于什么  基于lucene搜索库的一个搜索引擎框架，lucene是一个开放源码的全文检索引擎工具包  solr如何实现搜索的  倒排索引，先抽取文档中词，并建立词与文档id的映射关系，然后查询的时候会根据词去查询文档id，并查询出文档  Solr过滤器  Solr的过滤器对接收到的标记流（TokenStream ）做额外的处理 过滤查询，在查询时设置  solr怎么设置搜索结果排名靠前  设置文档中域的boost值，值越高相关性越高，排名就靠前  IK分词器原理  本质上是词典分词，在内存中初始化一个词典，然后在分词过程中逐个读取字符，和字典中的字符相匹配，把文档中的所有词语拆分出来的过程  solr的索引查询为什么比数据库要快  Solr使用的是Lucene API实现的全文检索。全文检索本质上是查询的索引。而数据库中并不是所有的字段都建立的索引，更何况如果使用like查询时很大的可能是不使用索引，所以使用solr查询时要比查数据库快  solr 实现全文检索  索引流程：客户端&amp;mdash;》solr 服务器(发送post请求,xml文档包含filed，solr实现对索引的维护)
 搜索流程：客户端&amp;mdash;》solr 服务器(发送get 请求，服务器返回一个xml 文档)
  solr和lucene的区别 Solr和Lucene的本质区别有以下三点：搜索服务器，企业级和管理。
 1、搜索服务器：Lucene本质上是搜索库，不是独立的应用程序，而Solr是。
 2、企业级：Lucene专注于搜索底层的建设，而Solr专注于企业应用。
 3、管理：Lucene不负责支撑搜索服务所必须的管理，而Solr负责。所以说，一句话概括Solr: Solr是Lucene面向企业搜索应用的扩展
 Lucene: 是一个索引与搜索类库，而不是完整的程序。
 Solr：是一个高性能，采用Java5开发，基于Lucene的一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。
  Elasticsearch 与 Solr 的比较： 共同点：</description>
            <content type="html"><![CDATA[

<h3 id="solr">Solr</h3>

<ul>
<li>Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。官网地址：<a href="http://lucene.apache.org/solr/" target="_blank">http://lucene.apache.org/solr/</a></li>
</ul>

<hr />

<h3 id="solr原理">Solr原理</h3>

<ul>
<li>Solr是基于Lucene开发的全文检索服务器，而Lucene就是一套实现了全文检索的api，其本质就是一个全文检索的过程。全文检索就是把原始文档根据一定的规则拆分成若干个关键词，然后根据关键词创建索引，当查询时先查询索引找到对应的关键词，并根据关键词找到对应的文档，也就是查询结果，最终把查询结果展示给用户的过程</li>
</ul>

<hr />

<h3 id="solrd倒排索引">Solrd倒排索引</h3>

<ul>
<li>我们传统的方式（正排索引）是从关键点出发，然后再通过关键点找到关键点代表的信息中能够满足搜索条件的特定信息，既通过KEY寻找VALUE。</li>
<li>而Solr的搜索则是采用了倒排索引的方式，即通过VALUE找KEY。而在中文全文搜索中VALUE就是我们要搜索的单词，存放所有单词的地方叫词典。KEY是文档标号列表（通过文档标号列表我们可以找到出现过要搜索单词VALUE的文档）</li>
</ul>

<hr />

<h3 id="solr基于什么">Solr基于什么</h3>

<ul>
<li>基于lucene搜索库的一个搜索引擎框架，lucene是一个开放源码的全文检索引擎工具包</li>
</ul>

<hr />

<h3 id="solr如何实现搜索的">solr如何实现搜索的</h3>

<ul>
<li>倒排索引，先抽取文档中词，并建立词与文档id的映射关系，然后查询的时候会根据词去查询文档id，并查询出文档</li>
</ul>

<hr />

<h3 id="solr过滤器">Solr过滤器</h3>

<ul>
<li>Solr的过滤器对接收到的标记流（TokenStream ）做额外的处理</li>
<li>过滤查询，在查询时设置</li>
</ul>

<hr />

<h3 id="solr怎么设置搜索结果排名靠前">solr怎么设置搜索结果排名靠前</h3>

<ul>
<li>设置文档中域的boost值，值越高相关性越高，排名就靠前</li>
</ul>

<hr />

<h3 id="ik分词器原理">IK分词器原理</h3>

<ul>
<li>本质上是词典分词，在内存中初始化一个词典，然后在分词过程中逐个读取字符，和字典中的字符相匹配，把文档中的所有词语拆分出来的过程</li>
</ul>

<hr />

<h3 id="solr的索引查询为什么比数据库要快">solr的索引查询为什么比数据库要快</h3>

<ul>
<li>Solr使用的是Lucene API实现的全文检索。全文检索本质上是查询的索引。而数据库中并不是所有的字段都建立的索引，更何况如果使用like查询时很大的可能是不使用索引，所以使用solr查询时要比查数据库快</li>
</ul>

<hr />

<h3 id="solr-实现全文检索">solr 实现全文检索</h3>

<ul>
<li><p>索引流程：客户端&mdash;》solr 服务器(发送post请求,xml文档包含filed，solr实现对索引的维护)</p></li>

<li><p>搜索流程：客户端&mdash;》solr 服务器(发送get 请求，服务器返回一个xml 文档)</p></li>
</ul>

<hr />

<h3 id="solr和lucene的区别">solr和lucene的区别</h3>

<p>Solr和Lucene的本质区别有以下三点：<strong>搜索服务器，企业级和管理。</strong></p>

<ul>
<li><p><strong>1、搜索服务器：</strong>Lucene本质上是搜索库，不是独立的应用程序，而Solr是。</p></li>

<li><p><strong>2、企业级：</strong>Lucene专注于搜索底层的建设，而Solr专注于企业应用。</p></li>

<li><p><strong>3、管理：</strong>Lucene不负责支撑搜索服务所必须的管理，而Solr负责。所以说，一句话概括Solr: Solr是Lucene面向企业搜索应用的扩展</p></li>

<li><p><strong>Lucene:</strong> 是一个索引与搜索类库，而不是完整的程序。</p></li>

<li><p><strong>Solr：</strong>是一个高性能，采用Java5开发，基于Lucene的一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。</p></li>
</ul>

<hr />

<h3 id="elasticsearch-与-solr-的比较">Elasticsearch 与 Solr 的比较：</h3>

<p><strong>共同点：</strong></p>

<ul>
<li>Solr和Elasticsearch都是基于Lucene实现的；</li>
</ul>

<p><strong>不同点：</strong></p>

<ul>
<li><p>1.Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能;</p></li>

<li><p>2.Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式；</p></li>

<li><p>3.Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供；</p></li>

<li><p>4.Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。</p></li>
</ul>

<hr />
]]></content>
        </item>
        
        <item>
            <title>Lucene、Solr和Elasticsearch介绍</title>
            <link>https://gj1e.github.io/posts/2019/10/lucenesolr%E5%92%8Celasticsearch%E4%BB%8B%E7%BB%8D/</link>
            <pubDate>Thu, 03 Oct 2019 15:15:44 +0800</pubDate>
            
            <guid>https://gj1e.github.io/posts/2019/10/lucenesolr%E5%92%8Celasticsearch%E4%BB%8B%E7%BB%8D/</guid>
            <description>Lucene和Solr和Elasticsearch的区别 Lucene  Lucene是apache下的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。官网地址：https://lucene.apache.org/  Solr  Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。官网地址：http://lucene.apache.org/solr/  Elasticsearch  Elasticsearch跟Solr一样，也是一个基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。官网地址：https://www.elastic.co/products/elasticsearch  Elasticsearch的优缺点： 优点：  1.Elasticsearch是分布式的。不需要其他组件，分发是实时的，被叫做”Push replication”。
 2.Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。
 3.处理多租户（multitenancy）不需要特殊配置，而Solr则需要更多的高级设置。
 4.Elasticsearch 采用 Gateway 的概念，使得完备份更加简单。
 5.各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。
  缺点：  1.只有一名开发者（当前Elasticsearch GitHub组织已经不只如此，已经有了相当活跃的维护者）
 2.还不够自动（不适合当前新的Index Warmup API）
  Solr的优缺点： 优点  1.Solr有一个更大、更成熟的用户、开发和贡献者社区。
 2.支持添加多种格式的索引，如：HTML、PDF、微软 Office 系列软件格式以及 JSON、XML、CSV 等纯文本格式。
 3.Solr比较成熟、稳定。
 4.不考虑建索引的同时进行搜索，速度更快。
  缺点  1.建立索引时，搜索效率下降，实时索引搜索效率不高。  Elasticsearch 与 Solr 的比较：  1.</description>
            <content type="html"><![CDATA[

<h2 id="lucene和solr和elasticsearch的区别">Lucene和Solr和Elasticsearch的区别</h2>

<h3 id="lucene">Lucene</h3>

<ul>
<li>Lucene是apache下的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。官网地址：<a href="https://lucene.apache.org/" target="_blank">https://lucene.apache.org/</a></li>
</ul>

<hr />

<h3 id="solr">Solr</h3>

<ul>
<li>Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。官网地址：<a href="http://lucene.apache.org/solr/" target="_blank">http://lucene.apache.org/solr/</a></li>
</ul>

<hr />

<h3 id="elasticsearch">Elasticsearch</h3>

<ul>
<li>Elasticsearch跟Solr一样，也是一个基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。官网地址：<a href="https://www.elastic.co/products/elasticsearch" target="_blank">https://www.elastic.co/products/elasticsearch</a></li>
</ul>

<hr />

<h2 id="elasticsearch的优缺点">Elasticsearch的优缺点：</h2>

<h3 id="优点">优点：</h3>

<ul>
<li><p>1.Elasticsearch是分布式的。不需要其他组件，分发是实时的，被叫做”Push replication”。</p></li>

<li><p>2.Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。</p></li>

<li><p>3.处理多租户（multitenancy）不需要特殊配置，而Solr则需要更多的高级设置。</p></li>

<li><p>4.Elasticsearch 采用 Gateway 的概念，使得完备份更加简单。</p></li>

<li><p>5.各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。</p></li>
</ul>

<hr />

<h3 id="缺点">缺点：</h3>

<ul>
<li><p>1.只有一名开发者（当前Elasticsearch GitHub组织已经不只如此，已经有了相当活跃的维护者）</p></li>

<li><p>2.还不够自动（不适合当前新的Index Warmup API）</p></li>
</ul>

<hr />

<h2 id="solr的优缺点">Solr的优缺点：</h2>

<h3 id="优点-1">优点</h3>

<ul>
<li><p>1.Solr有一个更大、更成熟的用户、开发和贡献者社区。</p></li>

<li><p>2.支持添加多种格式的索引，如：HTML、PDF、微软 Office 系列软件格式以及 JSON、XML、CSV 等纯文本格式。</p></li>

<li><p>3.Solr比较成熟、稳定。</p></li>

<li><p>4.不考虑建索引的同时进行搜索，速度更快。</p></li>
</ul>

<hr />

<h3 id="缺点-1">缺点</h3>

<ul>
<li>1.建立索引时，搜索效率下降，实时索引搜索效率不高。</li>
</ul>

<hr />

<h2 id="elasticsearch-与-solr-的比较">Elasticsearch 与 Solr 的比较：</h2>

<ul>
<li><p>1.二者安装都很简单；</p></li>

<li><p>2.Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能;</p></li>

<li><p>3.Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式；</p></li>

<li><p>4.Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供；</p></li>

<li><p>5.Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。</p></li>

<li><p>6.Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。</p></li>
</ul>

<h3 id="使用案例">使用案例：</h3>

<ul>
<li><p>1.维基百科使用Elasticsearch来进行全文搜做并高亮显示关键词，以及提供search-as-you-type、did-you-mean等搜索建议功能。</p></li>

<li><p>2.英国卫报使用Elasticsearch来处理访客日志，以便能将公众对不同文章的反应实时地反馈给各位编辑。</p></li>

<li><p>3.StackOverflow将全文搜索与地理位置和相关信息进行结合，以提供more-like-this相关问题的展现。</p></li>

<li><p>4.GitHub使用Elasticsearch来检索超过1300亿行代码。</p></li>

<li><p>5.每天，Goldman Sachs使用它来处理5TB数据的索引，还有很多投行使用它来分析股票市场的变动。</p></li>
</ul>

<hr />
]]></content>
        </item>
        
    </channel>
</rss>
