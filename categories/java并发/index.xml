<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Java并发 on Gao J1e&#39;s Blog</title>
    <link>https://gj1e.github.io/categories/java%E5%B9%B6%E5%8F%91/</link>
    <description>Recent content in Java并发 on Gao J1e&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>郜杰</copyright>
    <lastBuildDate>Wed, 18 Mar 2020 21:50:32 +0800</lastBuildDate>
    
	<atom:link href="https://gj1e.github.io/categories/java%E5%B9%B6%E5%8F%91/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ThreadLocal探秘</title>
      <link>https://gj1e.github.io/posts/2020/03/threadlocal%E6%8E%A2%E7%A7%98/</link>
      <pubDate>Wed, 18 Mar 2020 21:50:32 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2020/03/threadlocal%E6%8E%A2%E7%A7%98/</guid>
      <description>ThreadLocal被称作为线程本地变量，或者线程的本地存储。
ThreadLocal可以让每个线程绑定自己的值。
ThreadLocal将变量在每个线程中都创建了一个副本，这样每个线程就可以访问自己内部的副本变量，它们可以通过get（）和set（）方法来获取默认值，或者将变量设置为当前线程所要保存的副本的值，这样就能避免了线程安全的问题。
ThreadLocal原理 ThreadLocal内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，它的键值为当前ThreadLocal的变量，value为变量副本。ThreadLocalMap是ThreadLocal的一个内部类。
初始化时，在Thread里，threadLocals为空，通过ThreadLocal变量调用get或set方法就会对threadLocals进行初始化，并且以当前ThreadLocal变量为键值，value为当前ThreadLocal所要保存的值。
然后在当前线程里，如果要使用哪个ThreadLocal变量的副本值，就通过这个ThreadLocal的变量调用get（）方法来获取副本值。
ThreadLocal内存泄漏问题 ThreadLocalMap中使用的key为弱引用，而value为强引用，所以如果ThreadLocal没有被外部引用的情况下，在垃圾回收时，Key会被清理掉。这样，ThreadLocalMap中就会出现key为null的Entry。
如果我们不采取任何措施的话，value永远也无法被GC回收，这样就会产生内存泄露。
ThreadLocalMap实现中已经考虑了这种情况，所以在调用get（），set（），remove（）方法时会自动清理掉key为null的记录。</description>
    </item>
    
    <item>
      <title>ConcurrentHashMap探秘</title>
      <link>https://gj1e.github.io/posts/2020/03/concurrenthashmap%E6%8E%A2%E7%A7%98/</link>
      <pubDate>Wed, 18 Mar 2020 21:08:55 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2020/03/concurrenthashmap%E6%8E%A2%E7%A7%98/</guid>
      <description> 它是HashMap的多线程版本，是线程安全的。可以在并发环境下直接使用。为什么放着好好的HashTable不用又要从新实现一个ConcurrentHashMap呢？就是因为效率问题（虽然你安全，但是太慢了，没有爽感。）这个就不一样，即安全，效率还高，这酸爽你能顶的住？
ConcurrentHashMap是将数据分成一段一段存储，然后给每个数据段配一把锁，当一个线程访问占用启用一个数据段的同时，其它数据段也能被其他线程访问。（这种思想就类比公共厕所里的一排蹲坑就行。）
 注意：ConcurrentHashMap读不加锁，下文会有解释。
 ConcurrentHashMap之内部数据结构 JDK1.7： ConcurrentHashMap是由segment数组结构和HashEntry组成，segment实现了ReentrantLock，所以扮演了一个可重入锁的角色。HashEntry用于存储键值对数据。
一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。
 注意：初始化时容器里面默认的锁的个数，也就是Segment数组长度为16；具体解释可以看《Java并发编程艺术》P279
图片出处见参考
 JDK1.8： ConcurrentHashMap取消了分段锁，采用的CAS+Synchronized来保证并发安全。
数据结构和HashMap1.8的类似，数组+链表/红黑树。当链表长度大于8时，会将链表转为红黑树，来保证查询效率。 Synchronized只锁定当前链表的头节点，或红黑树的首节点。
 图片出处见参考
 ConcurrentHashMap的get（）方法 Segment的get操作非常高效，先经过一次再散列，然后使用这个散列值通过散 列运算定位到Segment，再通过散列算法定位到元素。整个过程时不加锁的，除非读到的值是空才会加锁重读。这就是比HashTable效率高的其中一个点。
为什么不（带）加（TT）锁，还能保证安全呢？
就是因为它的get方法里将要使用的共享变量都定义成了volatile类型了，（这操作真骚，直接从根儿上做了绝育）例如用来统计segment大小的count字段，和用于存储HashEntry的值value。
现在我们解释一下为啥定义成了volatile类型就可以保证安全了呢？
首先，volatile类型的变量可以保证线程之间的修改可见性，能够被多线程同时读取，并且还保证你读的值不过期，这就很骚。
但是有利有弊。缺点就是只能被单线程写，只有一种情况下可以被多线程写，呢就是要写入的值不依赖于原值。
为什么可以保证读到的值不是过期值呢？
因为happens-before原则嘛，任意对volatile类型变量的写，happens-before对这个变量的读。换成人话就是对volatile类型的变量的写操作优先于读操作。
ConcurrentHashMap的put（）方法 put方法需要对共享变量进行写操作，所以需要对操作的共享变量加锁，（真刀真枪的时候，还是加锁放心）。put方法是首先定位到具体的Segment，然后在Segment里进行数据的写入操作。整个的写入操作分为两步
第一步：首先判断是否需要扩容 插入元素之前，先判断Segment种的HashEntry数组是否达到阈值（threshlod），如果超过阈值则对数组进行扩容。（看到这里的时候想一想HashMap是先插入在判断，还是先判断再插入）在扩容时，首先会创建一个容量是原来2倍的数组，然后将原数组中的元素进行新一次散列，然后再插入到新数组中。
 注意：ConcurrentHashMap不会对整个容器进行扩容，而是只对某个Segment进行扩容。
 第二步：进行插入 将需要插入的元素通过散列定位，然后插入。（找准了，再插入）
ConcurrentHashMap的size（）方法 size（）方法就是来统计整个ConcurrentHashMap里元素的大小，也就是统计出每个segment的大小，然后求和。看似简单，但是细想又不是很简单，虽然，count是个volatile类型的全局变量，但是顶不住有其它线程在统计的时候捣乱呀。比如，当把所有的segment的大小求出准备进行相加时，又有其它线程对count进行了修改，这样统计的结果就不准确了。可是如果在统计过程中将其它方法锁住，呢岂不是效率太低了嘛？酸爽的体验感就有瑕疵了。
牛逼的大佬们给出的解决方案就是，先尝试2次不加锁进行统计，如果在统计过程中，count发生了变化，呢我再去加锁，再来进行统计。（有没有觉得很像自己，先裸爽，顶不住了在保护，既爽还持久，是不是很骚？）
那么是如何来感知count发生变化的呢？
使用了一个modCount变量，在put、remove和clean方法里操作元素前都会将变量modCount进行加1，那么在统计size 前后比较modCount是否发生变化，从而得知容器的大小是否发生变化。
 觉得有点CAS的味道。（个人感觉，感觉不对别喷我）
 参考  《Java并发编程的艺术》 大佬博客以及图片出处  </description>
    </item>
    
    <item>
      <title>生产者与消费者问题</title>
      <link>https://gj1e.github.io/posts/2019/12/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 07 Dec 2019 20:59:43 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/12/%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/</guid>
      <description>问题描述  生产者消费者问题（Producer-consumer problem），也称有限缓冲问题（Bounded-buffer problem），是一个多线程同步问题的经典案例。生产者生成一定量的数据放到缓冲区中，然后重复此过程；与此同时，消费者也在缓冲区消耗这些数据。生产者和消费者之间必须保持同步，要保证生产者不会在缓冲区满时放入数据，消费者也不会在缓冲区空时消耗数据。不够完善的解决方法容易出现死锁的情况，此时进程都在等待唤醒。  解决问题的核心  保证同一资源被多个线程并发访问时的完整性。常用的同步方法是采用信号或加锁机制，保证资源在任意时刻至多被一个线程访问。
代码实现 利用Synchronized，wait() / notify()方法实现
import java.util.LinkedList; /** * @Author GJ1e * @Create 2019/12/7 * @Time 19:09 * * 缓冲区 */ public class Storage { private final int STORAGE_MAX = 10; //缓冲区载体 private LinkedList&amp;lt;Object&amp;gt; list = new LinkedList&amp;lt;Object&amp;gt;(); public void proudce(){ synchronized(list){ while (list.size()+1 &amp;gt; 10){ System.out.println(&amp;quot;生产者&amp;quot;+Thread.currentThread().getName()+&amp;quot;仓库已满&amp;quot;); try { list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } list.add(new Object()); System.out.println(&amp;quot;生产者&amp;quot;+Thread.currentThread().getName() +&amp;quot;生产一个商品，现在库存为&amp;quot;+list.</description>
    </item>
    
    <item>
      <title>ReentrantLock</title>
      <link>https://gj1e.github.io/posts/2019/11/reentrantlock/</link>
      <pubDate>Fri, 08 Nov 2019 23:03:54 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/11/reentrantlock/</guid>
      <description>Reentrantlock是一个可重入锁，在高竞争条件下有更好的性能，且可以中断。
Reentrantlock是基于AQS实现的，AQS是基于FIFO队列实现的，整个AQS是典型的模板模式的应用，对于队列FIFO的各种操作，在AQS中都已经实现。AQS的子类一般只需要重写tryAcquire(int arg)尝试获得锁，和tryRlease(int arg)尝试释放锁两个方法即可。
Reentrantlock中有一个抽象类Sync继承于AbstractQueuedSynchronizer。
private final Sync sync; /** * Base of synchronization control for this lock. Subclassed * into fair and nonfair versions below. Uses AQS state to * represent the number of holds on the lock. */ abstract static class Sync extends AbstractQueuedSynchronizer { ... }  Reentrantlock根据传入构造函数的布尔类型的参数，实例化出Sync的实现类FairSync和NonfairSync，分别表示公平的Sync和非公平的Sync，也就是公平锁，和非公平锁。
以比较常用的非公平锁为例：
假设线程1，调用了Reentrantlock中的lock()方法那么线程1就会独占该锁。
线程1获得锁就做了两件事：
 设置AQS的state为1。
 设置AQS的Thread为当前线程。
  这两步做完之后就表示线程1独占了该锁。当线程2想要获得锁时，会尝试利用CAS去判断state状态是否为0，如果为0就设置为1。这一步操作肯定是失败的，因为线程1已经将state设置成了1。所以线程2就会执行lock()方法中的else分支调用acquire()方法，进而调用tryAcquire()方法，尝试获取一次锁，如果还是失败就会将这个线程加入到等待队列中。
Reentrantlock的使用场景  需要使用可重入锁时。
 并发竞争很高的环境下。
 需要使用可中断锁。
 尝试等待执行，如果发现已经在执行，则尝试等待一段时间。等待超时，则不执行。</description>
    </item>
    
    <item>
      <title>Volatile关键字</title>
      <link>https://gj1e.github.io/posts/2019/11/volatile%E5%85%B3%E9%94%AE%E5%AD%97/</link>
      <pubDate>Tue, 05 Nov 2019 17:07:31 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/11/volatile%E5%85%B3%E9%94%AE%E5%AD%97/</guid>
      <description>  volatile的本质是在告诉JVM当前变量在寄存器中的值是不确定的，需要从主存中读取。
 vloatile仅能使用在变量级别，仅能实现变量的修改可见性。但不具备原子性。
 volatile不会造成线程的阻塞。
 volatile标记的变量不会被编译器优化。
  volatile的不变性  将当前处理器缓存行的数据写回到系统内存。
 这个写回内存的操作会引起在其它CPU里缓存了该内存地址的数据无效。
  volatile禁止指令重排序  普通变量仅仅会保证在方法执行过程中所有依赖赋值的结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。  volatile与synchronized的区别(重点)  volatile、final、synchronized都可以实现可见性。
 volatile的本质是在告诉JVM当前变量在寄存器中的值是不确定的，需要从主存中读取。synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞。
 vloatile仅能使用在变量级别，synchronized可以使用在变量，方法和代码块。
 volatile仅能实现变量的修改可见性。但不具备原子性。而synchronized则可以保证变量的修改可见性和原子性。
 volatile不会造成线程的阻塞，而synchronized可能会造成线程阻塞。
 volatile标记的变量不会被编译器优化，而synchronized标记的变量可以被编译器优化。
  </description>
    </item>
    
    <item>
      <title>Synchronized关键字</title>
      <link>https://gj1e.github.io/posts/2019/11/synchronized%E5%85%B3%E9%94%AE%E5%AD%97/</link>
      <pubDate>Sun, 03 Nov 2019 16:35:53 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/11/synchronized%E5%85%B3%E9%94%AE%E5%AD%97/</guid>
      <description>synchronized关键字的作用  synchronized关键字解决的是多个线程之间访问资源的同步性。
 synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。
  怎么使用synchronized关键字 synchronized关键字最主要的三种使用方式：
 修饰实例方法：给当前对象实例加锁，进入同步代码块之前要先获得当前对象实例的锁。
 修饰静态方法：也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象。因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。
 修饰代码块：指定加锁对象，对给定对象加锁，进入同步代码块前要获得给定对象的锁。
  单例模式-双重校验锁 public class Singleton { private volatile static Singleton uniqueInstance; private Singleton() { } public static Singleton getUniqueInstance() { //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) { //类对象加锁 synchronized (Singleton.class) { if (uniqueInstance == null) { uniqueInstance = new Singleton(); } } } return uniqueInstance; } }  uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton();这段代码其实是分为三步执行：</description>
    </item>
    
    <item>
      <title>Java并发基础知识点</title>
      <link>https://gj1e.github.io/posts/2019/11/java%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/</link>
      <pubDate>Sun, 03 Nov 2019 15:21:25 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/11/java%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/</guid>
      <description>线程和进程  进程：进程是程序的一次执行过程，是系统运行程序的基本单位。进程是动态的，随着程序的运行而创建，结束就消亡。
 线程：与进程相似，比进程更小，一个进程在执行时可以产生多个线程。
   同类的多个线程可以共享进程的堆和方法区，但虚拟机，本地方法栈，程序计数器为线程私有。
 并发与并行  并发：同一时间段，多个任务都在执行(单位时间内不一定同时执行)
 并行：单位时间内多个任务同时执行。
  Java中的线程有几种状态  新建状态：新创建了一个线程对象。
 就绪状态：线程对象创建之后，其它线程调用了该对象的start()方法，此时线程处于就绪状态，并未运行，等待获取CPU的使用权。
 运行状态：就绪状态的线程获取到CPU的使用权之后，执行程序代码。
 阻塞状态：阻塞状态是线程因为某些原因放弃了CPU的使用权，暂停运行，直到线程到就绪态，才有机会再到运行状态。
 死亡状态：线程执行完了，或者线程因为异常退出了run()方法，该线程结束生命周期。
  死锁 线程A持有资源2，线程B持有资源1，他们都想申请对方的资源，然后这两个线程就会相互等待造成死锁。 产生死锁的条件  互斥条件：该资源任意时刻只能由一个线程占用。
 请求与保持条件：一个进程因请求资源而阻塞时，对已经获得资源保持不放。
 不可剥夺条件：线程已获得的资源在未使用完之前，不能被其它线程强行剥夺，只能自己释放。
 循环等待条件：若干个进程之间形成一种头尾相接的循环等待资源关系。
  如何避免死锁 破坏四个条件中的一个就好。
 破坏互斥条件：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的。
 破坏请求与保持条件：一次性申请所有资源。
 破坏不可剥夺条件：占用部分资源的线程申请其它资源，申请不到就主动释放自己占有的资源。
 破坏循环等待条件：按序申请资源，按反序释放资源。
  sleep()方法和wait()方法的区别和共同点  共同点：
 两者都可以暂停线程的执行。  区别：
 Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用wait(long timeout)超时后线程会自动苏醒。   为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？ new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。</description>
    </item>
    
  </channel>
</rss>