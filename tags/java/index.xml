<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Java on Gao J1e&#39;s Blog</title>
    <link>https://gj1e.github.io/tags/java/</link>
    <description>Recent content in Java on Gao J1e&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>郜杰</copyright>
    <lastBuildDate>Tue, 26 Nov 2019 20:25:20 +0800</lastBuildDate>
    
	<atom:link href="https://gj1e.github.io/tags/java/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Redis的持久化</title>
      <link>https://gj1e.github.io/posts/2019/11/redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96/</link>
      <pubDate>Tue, 26 Nov 2019 20:25:20 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/11/redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96/</guid>
      <description> Redis支持内存数据持久化，将存储在内存中的数据以某种形式持久化到硬盘中，Redis重启后仍能加载硬盘中的数据重新使用。
Redis有两种持久化方式：一种RDB，一种AOF。
 Redis默认的持久化方式为RDB，两种持久化方式可以单独使用，也可结合使用。
 RDB  RDB方式是通过快照来完成的，当符合一定的条件时，Redis会自动将内存中的所有数据进行快照并存储到硬盘上。进行快照的条件在配置文件中指定，有两个参数：时间和改动的键的个数。
 当在指定时间内被更改的键的个数大于指定数值时，就会进行快照。
 Redis在以RDB方式持久化数据时，是以一个子进程来做的，也就是说进行RDB持久化时，不会影响Redis的主进程对外的使用。
   RDB并不能绝对保证数据的不丢失
 RDB的快照过程：  Redis使用fork函数复制一份当前进程(父进程)的副本(子进程)。 父进程继续接受并处理客户端发来的命令，而子进程开始将内存中的数据写入到硬盘中的临时文件。 当子进程写入完所有数据后，会用该临时文件替换旧的RDB文件(默认是压缩过的)。   可以通过SAVE和BGSAVE命令来手动快照，前者是由主进程进行快照，会阻塞其它请求；后者是通过fork子进程来进行快照。
 AOF  AOF持久化策略是将发送到Redis端的每一条命令都记录下来，并保存到硬盘中的AOF文件，AOF文件和RDB文件位置相同。   AOF持久化方式是默认关闭的，通过配置文件中的appendonly参数设为YES开启。
AOF文件对于查询的操作不做记录。
 AOF文件到磁盘的同步策略  appendfsync always 每次都同步(最安全，但也最慢) appendfsync everysec 每秒同步（默认的同步策略） appendfsync no 不主动同步，由操作系统来决定   文件默认先写到缓存中，系统每30秒同步一次，才是真正写入到磁盘
 </description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>https://gj1e.github.io/posts/2019/11/redis/</link>
      <pubDate>Sun, 24 Nov 2019 18:48:38 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/11/redis/</guid>
      <description>什么是Redis  Redis是一个用C语言写的，开源、支持网络、基于内存、可选持久性的、非关系型、Key-Value数据库。它是一个内存中的数据结构存储系统，可以用作数据库，缓存和消息中间件。  使用Redis有哪些好处  速度快：因为数据结构在内存中类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
 支持丰富的数据类型：String，list，set，sorted set，hash
 支持事务：操作都是原子性，所谓原子性就是对数据的更改，要么全部执行，要么全部不执行。
 丰富的特性：可用于缓存，按Key设置过期时间，过期后将会自动删除。
  Redis和Memcached区别和比较  Redis不仅仅支持简单的k/v类型的数据，同时还提供string(字符串)、list(链表)、set(集合)、zset(sorted set &amp;ndash;有序集合)和hash（哈希类型）等数据结构的存储。 memcache支持简单的数据类型，String。
 Redis支持数据的备份，即master-slave模式的数据备份。
 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中
 redis的速度比memcached快很多
 Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型。
   有持久化需求或者对数据结构和处理有高级要求的应用，选择redis，其他简单的key/value存储，选择memcached。 对于两者的选择需要要看具体的应用场景，如果需要缓存的数据只是key-value这样简单的结构时，则还是采用memcache，它也足够的稳定可靠。 如果涉及到存储，排序等一系列复杂的操作时，毫无疑问选择redis。
 Redis有哪几种数据淘汰策略  volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据进行淘汰。
 volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据进行淘汰。
 volatile-random：从已设置过期时间的数据集中随机选择数据进行淘汰。
 allkeys-lru：从数据集中挑选最近最少使用的数据进行淘汰。
 allkeys-random：从数据集中随机选择数据进行淘汰。
 no-enviction：禁止淘汰数据。
  Redis的内存回收算法  LRU和引用计数器算法  Redis分布式锁 待总结。。。</description>
    </item>
    
    <item>
      <title>ZAB集群数据同步过程</title>
      <link>https://gj1e.github.io/posts/2019/10/zab%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Fri, 11 Oct 2019 10:36:18 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/10/zab%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%BF%87%E7%A8%8B/</guid>
      <description> ZXID zxid是Zookeeper中事务的全局唯一ID。
ZXID有两部分组成：一部分为Leader的选举周期Epoch值；一部分为事务的递增计数器
同步过程  对于准Leadr，所有的Follower会向准Leader发送一个自己最后一次接受的事务的Epoch值。
 当准Leader收到集群中过半的Follower发送的Epoch值之后，在这些Epoch值中选出一个最大值，将这个值+1得到新的Epoch值，并将这个新的Epoch值发送给集群中的Follower。
 当Follower收到准Leader发送的Epoch值后，会将其与自己的Epoch值进行比较，若小于，则更新自己的Epoch值为新的值，并向Leader发送ACK信息，ACK信息中包含了自己的Epoch值和自己的历史事务集合。
 Leader收到Follower发送的ACK信息之后，会在所有的历史事务集合中选出一个ZXID为最大的历史事务集合作为自己的初始化事务集合。
 准Leader将Epoch值与初始化事务集合发送给集群中过半的Follower。Leader会为每一个Follower准备一个队列，并将那些没有被各个Follower同步的事务，以Proposal的形式发送给各个Follower，并在后面追加Commint消息，表示该事务已经被提交。
 当Follower收到后，会接受并执行初始化事务集合，然后反馈给准Leader表明自己已处理。
 当Leader收到Follower的反馈后，会向Follower发送Commint消息，Follower收到Commit消息后提交事务，完成数据同步。
  </description>
    </item>
    
    <item>
      <title>Dubbo</title>
      <link>https://gj1e.github.io/posts/2019/10/dubbo/</link>
      <pubDate>Mon, 07 Oct 2019 20:53:26 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/10/dubbo/</guid>
      <description>Dubbo简介 Dubbo是一个分布式服务框架，以及SOA治理方案。其主要功能包括：
 高性能NIO通讯以多协议集成 服务动态寻址与路由 软负载均衡与容错 依赖分析与降级  Dubbo的五个节点  Provider：暴露服务的服务提供方
 Consumer：调用远程服务的服务消费方
 Registry：服务注册与发现的中心
 Monitor ：统计服务的调用次数和调用时间的监控中心
 Container：服务运行容器
  Dubbo节点的调用过程  服务容器负责启动、加载，运行服务提供者
 服务提供者在启动时，向注册中心注册自己提供的服务
 服务消费者在启动时，向注册中心订阅自己所需的服务
 注册中心返回服务提供者地址列表给服务消费者。如果有变更，注册中心会基于长链接推送变更数据给服务消费者
 服务消费者从服务提供者地址列表中，基于软负载均衡算法选一台服务提供者进行调用。如果调用失败，再另选一台
 服务消费者和服务提供者，把在内存中累计调用次数和调用时间，定时每分钟向注册中心发送一次数据。
  Dubbo的四个特性  连通性：
 说明它们之间都存在着联系。例如Provider，Consumer和Registry三者之间都是长链接，而Provider，Consumer向Registry注册服务以及订阅服务的时间都得向Monitor汇报。  健壮性：
 说明具有稳定性，例如注册中心中的对等集群中任意一台服务器宕掉后，将会自动切换到另一台。就算注册中心全部宕掉，服务者和消费者依然可以通过本地缓存进行通讯。  伸缩性：
 可以通过增加机器部署实例进行添加新的注册中心和服务提供者。  升级性：
 就是对未来架构的设想，比起目前框架，它的特点是可以实现自动部署服务的本地代理，以及可以通过访问压力来自动增减服务提供者。   Dubbo的RPC  RPC(Remote Procedure Call)远程过程调用，他是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。 RPC协议假定某些传输协议的存在，如TCP,UDP,为通信程序之间携带信息数据。RPC使得开发网络分布式程序变得更加容易。
 Dubbo RPC调用过程  Client服务消费方以本地调用的方式调用服务。
 Client Stub接收到调用后负责将方法、参数等组装成可以进行网络传输的消息体。</description>
    </item>
    
    <item>
      <title>Zookeeper</title>
      <link>https://gj1e.github.io/posts/2019/10/zookeeper/</link>
      <pubDate>Mon, 07 Oct 2019 16:50:14 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/10/zookeeper/</guid>
      <description>简介  ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 &amp;mdash;百度百科
 ZooKeeper集群整体框架  Client：客户端。每个Client都可以去访问这个Zookeeper集群提供的服务。 Sever：服务器。为客户端提供服务。  Zookeeper把集群划分为三种角色：Leader，Follower，Observer(Zookeeper3.3引入)
 Leader：是所有的Follower通过选举产生的的一个主节点，它负责处理客户端所有的事务请求和集群中各服务器的调度。
 Follower：
 处理客户端非事务请求并转发事务请求给Leader。 参与Leader发起的事务请求提议的投票。（Leader发起提案，要求Follower进行投票，需要半数以上的Follower节点通过，Leader才会Commit数据）  Observer：与Follower一样，不同的是Observer不参与Leader选举，也不参与过半写成功策略。（Obsever的目的是为了在不影响集群写性能的前提下提升集群的读性能）
  事务与非事务请求的处理流程  事务：Client&amp;ndash;&amp;gt;Sever(Follower)发送一个请求，然后判断是一个事务请求，Follower就会把这个请求转发给Leader进行处理。
 非事务：Client&amp;ndash;&amp;gt;Sever(Follower)发送一个请求，然后判断是一个非事务请求，Follower就会直接处理给予响应。
  综上可以得出Zookeeper适合以查询（读操作）为主的业务场景，并不适合以事务修改（写操作）为主的业务场景。
 Zookeeper支持横向扩展，横向扩展只能加强Zookeeper非事务请求的处理，不能加强事务请求的处理，因为无论怎么横向扩展，也只能有一个Leader。
 客户端怎么判断向集群中哪个Sever发起请求  客户端自己维护着一份节点列表，它会有一个选择节点的算法，可以随机或者可以按照轮巡这种算法来选择一个节点进行请求。  Zookeeper节点类型  Znode有三种类型，临时的（Ephemeral）持久的（Persistent）和顺序的（Sequence） 临时Znode的生命周期与客户端会话相关，客户端会话结束时，Zookeeper会将临时Znode删除，临时Znode不可以有子节点 持久Znode不依赖于客户端会话，只有当客户端明确要删除该持久Znode时，才会被删除。 Znode类型在创建时确定，并且之后不能再修改 顺序Znode可以分为临时顺序节点和持久顺序节点。  持久顺序节点：客户端与Zookeeper断开连接之后该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号。 临时顺序节点：客户端与Zookeeper断开连接之后该节点会被删除，只是Zookeeper给该节点名称进行顺序编号。   Zookeeper数据模型  层次化目录结构，命名符合常规系统规范。
 每个节点在Zookeeper种叫做Znode，并且有一个唯一的路径标识。
 节点Znode可以包含数据和子节点，但是临时类型的节点不能有子节点。
 Znode种的数据可以有多个版本，比如某一个路径下有多个数据版本，那么查询这个路径下的数据就要带上版本。
  Zookeeper读写机制  Zookeeper是一个由多个Sever组成的集群。
 集群中只能有一个Leader，可以有多个Follower。
 每个Follower保存一份数据副本。
 全局数据一直</description>
    </item>
    
    <item>
      <title>Memcached</title>
      <link>https://gj1e.github.io/posts/2019/10/memcached/</link>
      <pubDate>Fri, 04 Oct 2019 10:33:42 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/10/memcached/</guid>
      <description>简介Memchahed  Memcached是高性能分布式内存缓存服务器，它通过缓存数据库查询结果，减少对数据库的访问次数以提高动态Web应用的速度，提高可扩展性。 Memcached的API使用32位元的CRC(循环冗余校验)校验，计算键值后，将资料分散在不同的机器上，当表格满了以后，接下来新增的资料会以LRU机制替换掉。 Memcached基于一个存储键/值对的Hashmap。其守护进程是用C写的，但是客户端可以用任何语言来写，并通过mencached协议与其守护进程通信。  Memcached分布式算法 余数哈希  根据服务器的台数的余数进行分散。求得键的哈希值，再除以服务器的台数，根据余数选择服务器。  缺点：
 当添加或移除服务器时，缓存重组代价太大。当添加服务器要进行重哈希，会导致原来的服务器序号变了，按原来的逻辑寻找数据就会找不到，访问数据Memcached命中率下降，那么就会增加数据库服务器的负载。  一致性哈希  一致性hash算法通过一个叫作一致性hash环的数据结构实现。这个环的起点是0，终点是2^32 - 1，并且起点与终点连接，环的中间的整数按逆时针分布，故这个环的整数分布范围是[0, 2^32-1] 首先求出memcached服务器（节点）的哈希值，并将其配置到0~2^32-1的圆（continuum）上。 然后用同样的方法求出存储数据的键的哈希值，并映射到圆上。  然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过2^32-1仍然找不到服务器，就会保存到第一台memcached服务器上。   在Consistent Hashing中，只有在continuum上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响。
 Memcached的数据清除算法  LRU。每个slab会维护一个队列，刚插入的数据在队头，经常get的数据也会移动到队头，这样较老或者访问较少的数据相对都留在队尾。
 该算法从队尾开始淘汰，当slab分配不到足够的内存时，首先会检查队尾是否有过期数据。如果有的话会直接将其覆盖为新的对象，如果没有，会开始淘汰队尾的对象。
   Slab是一个内存块，它是memcached一次申请内存的最小单位。Slab的大小固定为1M（1048576 Byte），一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。
 描述一下Memcacehd的工作流程  先检查客户端的请求数据是否在memcached中，如有，直接把请求数据返回，不再对数据库进行任何操作； 如果请求的数据不在memcached中，就去查数据库，把从数据库中获取的数据返回给客户端，同时把数据缓存一份到memcached中（memcached客户端不负责，需要程序明确实现）； 每次更新数据库的同时更新memcached中的数据，保证一致性； 当分配给memcached内存空间用完之后，会使用LRU（Least Recently Used，最近最少使用）策略加上到期失效策略，失效数据首先被替换，然后再替换掉最近未使用的数据。  Memcached 和 Redis的区别  Redis不仅仅支持简单的k/v类型的数据，同时还提供string(字符串)、list(链表)、set(集合)、zset(sorted set &amp;ndash;有序集合)和hash（哈希类型）等数据结构的存储。 memcache支持简单的数据类型，String。
 Redis支持数据的备份，即master-slave模式的数据备份。
 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中
 redis的速度比memcached快很多
 Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型。
   有持久化需求或者对数据结构和处理有高级要求的应用，选择redis，其他简单的key/value存储，选择memcached。 对于两者的选择需要要看具体的应用场景，如果需要缓存的数据只是key-value这样简单的结构时，则还是采用memcache，它也足够的稳定可靠。 如果涉及到存储，排序等一系列复杂的操作时，毫无疑问选择redis。</description>
    </item>
    
    <item>
      <title>Solr</title>
      <link>https://gj1e.github.io/posts/2019/10/solr/</link>
      <pubDate>Fri, 04 Oct 2019 09:36:34 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/10/solr/</guid>
      <description>Solr  Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。官网地址：http://lucene.apache.org/solr/  Solr原理  Solr是基于Lucene开发的全文检索服务器，而Lucene就是一套实现了全文检索的api，其本质就是一个全文检索的过程。全文检索就是把原始文档根据一定的规则拆分成若干个关键词，然后根据关键词创建索引，当查询时先查询索引找到对应的关键词，并根据关键词找到对应的文档，也就是查询结果，最终把查询结果展示给用户的过程  Solrd倒排索引  我们传统的方式（正排索引）是从关键点出发，然后再通过关键点找到关键点代表的信息中能够满足搜索条件的特定信息，既通过KEY寻找VALUE。 而Solr的搜索则是采用了倒排索引的方式，即通过VALUE找KEY。而在中文全文搜索中VALUE就是我们要搜索的单词，存放所有单词的地方叫词典。KEY是文档标号列表（通过文档标号列表我们可以找到出现过要搜索单词VALUE的文档）  Solr基于什么  基于lucene搜索库的一个搜索引擎框架，lucene是一个开放源码的全文检索引擎工具包  solr如何实现搜索的  倒排索引，先抽取文档中词，并建立词与文档id的映射关系，然后查询的时候会根据词去查询文档id，并查询出文档  Solr过滤器  Solr的过滤器对接收到的标记流（TokenStream ）做额外的处理 过滤查询，在查询时设置  solr怎么设置搜索结果排名靠前  设置文档中域的boost值，值越高相关性越高，排名就靠前  IK分词器原理  本质上是词典分词，在内存中初始化一个词典，然后在分词过程中逐个读取字符，和字典中的字符相匹配，把文档中的所有词语拆分出来的过程  solr的索引查询为什么比数据库要快  Solr使用的是Lucene API实现的全文检索。全文检索本质上是查询的索引。而数据库中并不是所有的字段都建立的索引，更何况如果使用like查询时很大的可能是不使用索引，所以使用solr查询时要比查数据库快  solr 实现全文检索  索引流程：客户端&amp;mdash;》solr 服务器(发送post请求,xml文档包含filed，solr实现对索引的维护)
 搜索流程：客户端&amp;mdash;》solr 服务器(发送get 请求，服务器返回一个xml 文档)
  solr和lucene的区别 Solr和Lucene的本质区别有以下三点：搜索服务器，企业级和管理。
 1、搜索服务器：Lucene本质上是搜索库，不是独立的应用程序，而Solr是。
 2、企业级：Lucene专注于搜索底层的建设，而Solr专注于企业应用。
 3、管理：Lucene不负责支撑搜索服务所必须的管理，而Solr负责。所以说，一句话概括Solr: Solr是Lucene面向企业搜索应用的扩展
 Lucene: 是一个索引与搜索类库，而不是完整的程序。
 Solr：是一个高性能，采用Java5开发，基于Lucene的一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。
  Elasticsearch 与 Solr 的比较： 共同点：</description>
    </item>
    
    <item>
      <title>Lucene、Solr和Elasticsearch介绍</title>
      <link>https://gj1e.github.io/posts/2019/10/lucenesolr%E5%92%8Celasticsearch%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Thu, 03 Oct 2019 15:15:44 +0800</pubDate>
      
      <guid>https://gj1e.github.io/posts/2019/10/lucenesolr%E5%92%8Celasticsearch%E4%BB%8B%E7%BB%8D/</guid>
      <description>Lucene和Solr和Elasticsearch的区别 Lucene  Lucene是apache下的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。官网地址：https://lucene.apache.org/  Solr  Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。官网地址：http://lucene.apache.org/solr/  Elasticsearch  Elasticsearch跟Solr一样，也是一个基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。官网地址：https://www.elastic.co/products/elasticsearch  Elasticsearch的优缺点： 优点：  1.Elasticsearch是分布式的。不需要其他组件，分发是实时的，被叫做”Push replication”。
 2.Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。
 3.处理多租户（multitenancy）不需要特殊配置，而Solr则需要更多的高级设置。
 4.Elasticsearch 采用 Gateway 的概念，使得完备份更加简单。
 5.各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。
  缺点：  1.只有一名开发者（当前Elasticsearch GitHub组织已经不只如此，已经有了相当活跃的维护者）
 2.还不够自动（不适合当前新的Index Warmup API）
  Solr的优缺点： 优点  1.Solr有一个更大、更成熟的用户、开发和贡献者社区。
 2.支持添加多种格式的索引，如：HTML、PDF、微软 Office 系列软件格式以及 JSON、XML、CSV 等纯文本格式。
 3.Solr比较成熟、稳定。
 4.不考虑建索引的同时进行搜索，速度更快。
  缺点  1.建立索引时，搜索效率下降，实时索引搜索效率不高。  Elasticsearch 与 Solr 的比较：  1.</description>
    </item>
    
  </channel>
</rss>